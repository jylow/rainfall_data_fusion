{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485aa0d4",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf5923",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models.kriging import kriging_external_drift\n",
    "import tqdm as tqdm\n",
    "\n",
    "from utils.load import load_radar_dataset, load_raingauge_dataset, load_cml_dataset, read_config, get_gauge_coordinate_mappings\n",
    "from utils.visualisation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ff9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config('config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d8846",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037836de",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_df = load_radar_dataset(folder_name='sg_radar_data')\n",
    "raingauge_df = load_raingauge_dataset('rainfall_data.csv', N=0)\n",
    "cml_df = load_cml_dataset('CML_data_processed_2025.nc')\n",
    "print(radar_df.shape)\n",
    "print(raingauge_df.shape)\n",
    "print(cml_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f85a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = raingauge_df.copy()\n",
    "\n",
    "fifteen_min_total = temp.resample('15min').sum().mul(4) #resamples to 15 mins and converts to mm/hour rainfall rate\n",
    "raingauge_rate_df_15mins = fifteen_min_total\n",
    "\n",
    "raingauge_rate_df_5mins = raingauge_df.mul(12) #converts rainrate to instantaneous rainrate(at 5 mins interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f2e33",
   "metadata": {},
   "source": [
    "# Filter for only stations whos coordinates we know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62edbeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raingauge_sampling_method = \"15mins\"\n",
    "\n",
    "station_dict = get_gauge_coordinate_mappings()\n",
    "filter_cols = [s for s in raingauge_df.columns]\n",
    "\n",
    "if raingauge_sampling_method == \"5mins\":\n",
    "  station_aligned_raingauge_df = raingauge_rate_df_5mins[filter_cols]\n",
    "elif raingauge_sampling_method == \"15mins\":\n",
    "  station_aligned_raingauge_df = raingauge_rate_df_15mins[filter_cols]\n",
    "print(filter_cols)\n",
    "\n",
    "raingauge_station_count = len(filter_cols)\n",
    "\n",
    "#Count the number of na values per col\n",
    "nan_values = []\n",
    "for col in filter_cols:\n",
    "  column_data = station_aligned_raingauge_df[col].values\n",
    "  nans = np.sum(np.count_nonzero(column_data))\n",
    "  nan_values.append(nans)\n",
    "\n",
    "print(raingauge_rate_df_15mins)\n",
    "plt.figure()\n",
    "plt.title(\"number of non-zero per station\")\n",
    "plt.hist(nan_values, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ba6da",
   "metadata": {},
   "source": [
    "# MERGE RADAR DATA AND RAIN GAUGE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(station_aligned_raingauge_df, radar_df, on='time_sgt', how='inner').fillna(0) # Hacky solutions for now. Need to figure out what to do with na values\n",
    "\n",
    "# print(merged_df)\n",
    "avg = merged_df.values[:, 1:-4].mean()\n",
    "min = merged_df.values[:, 1:-4].min()\n",
    "max = merged_df.values[:, 1:-4].max()\n",
    "\n",
    "print(f\"min: {min}, max: {max}, average: {avg}\")\n",
    "flattened_arr = merged_df.values[:, 1:-4].flatten()\n",
    "\n",
    "plt.hist(flattened_arr, bins=100, log=True)\n",
    "plt.title(f\"Raingauge readings sampled at {raingauge_sampling_method}\")\n",
    "plt.xlabel(\"Rainfall rate (mm/h)\")\n",
    "plt.ylabel(\"Count (Log scale)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3752951",
   "metadata": {},
   "source": [
    "ATTEMPT AT KRIGING BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a829b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrige.uk import UniversalKriging\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "variogram_model = \"gaussian\"\n",
    "\n",
    "row_data = merged_df.iloc[2].dropna()\n",
    "print(row_data)\n",
    "station_names = list(row_data.index[:-4])\n",
    "\n",
    "data = []\n",
    "\n",
    "for s in station_names[1:]:\n",
    "  lat, long = station_dict[s]\n",
    "  data.append([long, lat, row_data[s]])\n",
    "\n",
    "gauge_data = np.array(data)\n",
    "\n",
    "gridx = np.arange(103.605, 104.05, 0.01)\n",
    "gridy = np.arange(1.145, 1.51, 0.01)\n",
    "\n",
    "#RADAR FOR USE IN EXTERNAL DRIFT\n",
    "\n",
    "radar_grid = row_data['data']\n",
    "bounds = row_data['bounds']\n",
    "transform = row_data['transform']\n",
    "x_min = bounds.left\n",
    "y_max = bounds.top\n",
    "pixel_width = transform[0]\n",
    "pixel_height = -transform[4]\n",
    "\n",
    "axes[0].imshow(radar_grid, origin='lower')\n",
    "\n",
    "e_d = []\n",
    "e_dx = []\n",
    "e_dy = []\n",
    "\n",
    "for row in range(radar_grid.shape[0]): \n",
    "    y = y_max - (row * pixel_height) + pixel_height / 2\n",
    "    e_dy.append(y)\n",
    "\n",
    "for col in range(radar_grid.shape[0]):\n",
    "\n",
    "    # Calculate middle of cell\n",
    "    x = x_min + (col * pixel_width) + pixel_width / 2\n",
    "    e_dx.append(x)\n",
    "\n",
    "\n",
    "e_dx = np.array(e_dx)\n",
    "e_dy = np.array(e_dy)\n",
    "\n",
    "KED = UniversalKriging(\n",
    "    x=gauge_data[:, 0],\n",
    "    y=gauge_data[:, 1],\n",
    "    z=gauge_data[:, 2],\n",
    "    variogram_model=variogram_model,\n",
    "    drift_terms=[\"external_Z\"],\n",
    "    external_drift=radar_grid,\n",
    "    external_drift_x=e_dx,\n",
    "    external_drift_y=e_dy,\n",
    "    pseudo_inv=True\n",
    ")\n",
    "\n",
    "UK = UniversalKriging(\n",
    "    gauge_data[:, 0],\n",
    "    gauge_data[:, 1],\n",
    "    gauge_data[:, 2],\n",
    "    variogram_model=variogram_model,\n",
    "    drift_terms=[\"regional_linear\"],\n",
    "    pseudo_inv=True\n",
    ")\n",
    "\n",
    "\n",
    "z,ss = KED.execute(\"grid\", gridx, gridy)\n",
    "z2,ss2 = UK.execute(\"grid\", gridx, gridy)\n",
    "\n",
    "axes[1].imshow(z, origin='lower') #UKriging with external drift\n",
    "axes[2].imshow(z2, origin='lower') #Universal kriging\n",
    "plt.show()\n",
    "\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb79264",
   "metadata": {},
   "source": [
    "# Calculate Kriging Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "total_RMSE_loss = 0.0\n",
    "invalid_kriges = 0\n",
    "count = 0\n",
    "training_ratio = config['dataset_parameters']['train_size']\n",
    "station_names = list(merged_df.columns[:-4])\n",
    "station_names.remove('time_sgt')\n",
    "training_stations = random.sample(station_names, int(len(station_names) * training_ratio))\n",
    "validation_stations = [s for s in station_names if s not in training_stations]\n",
    "loss_arr = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(merged_df))):\n",
    "  count += 1\n",
    "  df = merged_df.iloc[i]\n",
    "  station_names=list(df.index[:-4]) #HARDCODED\n",
    "  station_names.remove('time_sgt')\n",
    "\n",
    "  kriging_result, keiging_variance = kriging_external_drift(df=df, \n",
    "                                                            station_names=training_stations, \n",
    "                                                            station_dict=station_dict, \n",
    "                                                            variogram_model='hole-effect', \n",
    "                                                            method='universal')\n",
    "  # print(kriging_result) #kriging_result[row][col]\n",
    "  # plt.imshow(kriging_result, origin='lower')\n",
    "  if kriging_result is None:\n",
    "    invalid_kriges += 1\n",
    "    continue\n",
    "\n",
    "  #Calculate loss\n",
    "  total_RSE_loss = 0.0\n",
    "  station_count = 0\n",
    "  for validation_station in validation_stations:\n",
    "    rain_gauge_value = df[validation_station]\n",
    "    lat, long = station_dict[validation_station]\n",
    "    row = math.floor((lat - 1.14) / 0.01)\n",
    "    col = math.floor((long - 103.6) / 0.01)\n",
    "    kriged_value = kriging_result[row][col]\n",
    "\n",
    "    error = math.sqrt((kriged_value - rain_gauge_value) ** 2)\n",
    "    total_RSE_loss += error\n",
    "    station_count += 1\n",
    "\n",
    "  RMSE = total_RSE_loss / station_count\n",
    "  loss_arr.append(RMSE)\n",
    "  total_RMSE_loss += RMSE\n",
    "  # print(f\"RMSE: {RMSE}\")\n",
    "\n",
    "print(f\"final average loss: {total_RMSE_loss / (len(merged_df)-invalid_kriges)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737daf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KED_Loss = loss_arr\n",
    "print(max(loss_arr))\n",
    "plt.hist(KED_Loss, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Universal_Loss = loss_arr\n",
    "print(max(Universal_Loss))\n",
    "plt.hist(Universal_Loss, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_Loss = loss_arr\n",
    "print(max(ordinary_Loss))\n",
    "plt.hist(ordinary_Loss, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a69662",
   "metadata": {},
   "source": [
    "# Plot raingauge and radar data on the same grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627bd125",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abad16b6",
   "metadata": {},
   "source": [
    "# General plotting function (Hard coded for max 9 plots for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d504bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1\n",
    "C = 1\n",
    "\n",
    "fig, ax = plt.subplots(R, C, figsize=(17,12))\n",
    "\n",
    "bounds_singapore = {\n",
    "  'left': 103.6,\n",
    "  'right': 104.05,\n",
    "  'top': 1.5,\n",
    "  'bottom': 1.188\n",
    "}\n",
    "\n",
    "# #iterrate through rows\n",
    "# for index, row in merged_df.head(R * C).iterrows():\n",
    "#   node_df = pandas_to_geodataframe(row)\n",
    "#   radar_input = row[['data', 'bounds', 'crs', 'transform']]\n",
    "#   visualise_gauge_grid(node_df=node_df, ax=ax[int(index / 2)][index % 2])\n",
    "#   visualise_radar_grid(data=radar_input, ax=ax[int(index / 2)][index % 2], zoom=None, scaling=None, alpha=0.5, legend=False)\n",
    "#   cx.add_basemap(ax, crs=4326, source=cx.providers.CartoDB.Voyager)\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "#single plot\n",
    "for index, row in merged_df[2:].head(1).iterrows():\n",
    "  node_df = pandas_to_geodataframe(row)\n",
    "  radar_input = row[['data', 'bounds', 'crs', 'transform']]\n",
    "  visualise_gauge_grid(node_df=node_df, ax=ax)\n",
    "  visualise_radar_grid(data=radar_input, ax=ax, zoom=bounds_singapore, scaling=None, alpha=0.5, legend=False)\n",
    "  cx.add_basemap(ax, crs=4326, source=cx.providers.CartoDB.Voyager)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5808a",
   "metadata": {},
   "source": [
    "# TEMP: Load CML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f1e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fdb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "cml_df.rename(columns={'time': 'time_sgt'}, inplace=True)\n",
    "cml_df['lat'] = (cml_df['site_a_latitude'] + cml_df['site_b_latitude'])/2\n",
    "cml_df['lon'] = (cml_df['site_a_longitude'] + cml_df['site_b_longitude'])/2\n",
    "\n",
    "# #vals = ['trsl', 'wet', 'baseline', 'waa', 'A', 'R','frequency', 'length', 'lat', 'lon']\n",
    "# vals = ['R', 'frequency', 'lat','lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = list(cml_df.columns.drop(['time_sgt', 'link_id', 'station']))\n",
    "df_pivoted = cml_df.pivot(index='time_sgt', columns=['link_id', 'station'], values='R')\n",
    "print(df_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8aeabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result contains the average rainfall rate between station A, B for each location\n",
    "\n",
    "df_result = df_pivoted.groupby(level=0, axis=1).agg('mean')\n",
    "df_result = df_result.reset_index()\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e196ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6143a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pivoted = cml_df.pivot(index='time_sgt', columns=['link_id', 'station'], values=vals)\n",
    "\n",
    "# def process_row(row):\n",
    "#     x = row.tolist()\n",
    "#     new_row = []\n",
    "#     print(x)\n",
    "#     new_row.append(x[0]) #freq\n",
    "#     new_row.append(x[2]) #lat\n",
    "#     new_row.append(x[4]) #lon\n",
    "#     new_row.append((x[6] + x[7]) / 2)\n",
    "#     return new_row\n",
    "\n",
    "# def combine_stations_and_values_v1(df_pivoted):\n",
    "#     \"\"\"\n",
    "#     Combine stations and aggregate values into arrays using groupby\n",
    "#     (I don't really know how this works. But the output is [R, R, frequency, frequency, lat, lat, lon, lon, trslA, trslB])\n",
    "#     \"\"\"\n",
    "#     # Stack to convert columns to rows, keeping time_sgt as index\n",
    "#     stacked = df_pivoted.stack(level=[0, 1, 2])  # Stack all column levels\n",
    "#     stacked = stacked.reset_index()\n",
    "    \n",
    "#     # Rename columns for clarity\n",
    "#     stacked.columns = ['time_sgt', 'value_type', 'link_id', 'station', 'value']\n",
    "    \n",
    "#     # Group by time_sgt and link_id, then aggregate all values into lists\n",
    "#     result = stacked.groupby(['time_sgt', 'link_id'])['value'].apply(\n",
    "#         process_row  # Remove NaN values and convert to list\n",
    "#     ).unstack(level='link_id')\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# df_result = combine_stations_and_values_v1(df_pivoted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result = df_result.reset_index()\n",
    "# print(df_result.reset_index().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources_df = pd.merge(copied_df, df_result, on='time_sgt', how='inner')\n",
    "print(all_sources_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c6307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pivoted = cml_df.pivot_table(index='time', columns=['link_id', 'station'], values='R')\n",
    "# df_pivoted.columns = [f'{link_id}_{station}' for link_id, station in df_pivoted.columns]\n",
    "# df_pivoted = df_pivoted.reset_index()\n",
    "# df_pivoted.rename(columns={'time': 'time_sgt'}, inplace=True)\n",
    "\n",
    "# copied_df = merged_df.copy()\n",
    "# copied_df = pd.merge(copied_df, df_pivoted, on='time_sgt', how='inner')\n",
    "# print(copied_df.iloc[0])\n",
    "\n",
    "\n",
    "# pd_df.rename(columns={'time_sg': 'time_sgt'}, inplace=True)\n",
    "# print(pd_df)\n",
    "# print(merged_df)\n",
    "# merged_df = pd.merge(pd_df, merged_df, on='time_sgt', how='inner')\n",
    "# print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac006f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get coordinate points for each station in CML\n",
    "# print(cml_df)\n",
    "\n",
    "cml_coordinate_info = cml_df[['link_id', 'lat', 'lon']]\n",
    "cml_coordinate_info = cml_coordinate_info.groupby('link_id').agg('mean')\n",
    "\n",
    "print(cml_coordinate_info.loc('AMK_1012_1655_59-ODU_25-ODU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_scattered_to_grid(scattered_x, scattered_y, scattered_values, \n",
    "                                  grid_x, grid_y, method='linear'):\n",
    "    \"\"\"\n",
    "    Interpolate scattered point data to a regular grid\n",
    "    \"\"\"\n",
    "    from scipy.interpolate import griddata\n",
    "    \n",
    "    # Create grid points\n",
    "    X_grid, Y_grid = np.meshgrid(grid_x, grid_y)\n",
    "    grid_points = np.column_stack([X_grid.ravel(), Y_grid.ravel()])\n",
    "    \n",
    "    # Interpolate scattered data to grid\n",
    "    scattered_points = np.column_stack([scattered_x, scattered_y])\n",
    "\n",
    "    interpolated_values = griddata(\n",
    "        scattered_points, \n",
    "        scattered_values, \n",
    "        grid_points, \n",
    "        method=method,\n",
    "        fill_value=np.nan\n",
    "    )\n",
    "    \n",
    "    # Reshape back to grid\n",
    "    return interpolated_values.reshape(X_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76407237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrige.uk import UniversalKriging\n",
    "\n",
    "variogram_model = \"gaussian\"\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "row_data = all_sources_df.iloc[3].dropna()\n",
    "\n",
    "raingauge_station_names = list(row_data.index[:raingauge_station_count])\n",
    "cml_station_names = list(row_data.index[raingauge_station_count + 5:])\n",
    "\n",
    "data = [] #initialise array\n",
    "\n",
    "for s in raingauge_station_names[2:]:\n",
    "  lat, long = station_dict[s]\n",
    "  data.append([long, lat, row_data[s]])\n",
    "\n",
    "gauge_data = np.array(data)\n",
    " \n",
    "data = [] #initialise array\n",
    "\n",
    "for s in cml_station_names:\n",
    "   lat, lon = cml_coordinate_info.loc[s]\n",
    "   data.append([lon, lat, row_data[s]])\n",
    "\n",
    "cml_data = np.array(data)\n",
    "\n",
    "gridx = np.arange(103.605, 104.05, 0.01)\n",
    "gridy = np.arange(1.145, 1.51, 0.01)\n",
    "\n",
    "#RADAR FOR USE IN EXTERNAL DRIFT\n",
    "\n",
    "radar_grid = row_data['data']\n",
    "bounds = row_data['bounds']\n",
    "transform = row_data['transform']\n",
    "x_min = bounds.left\n",
    "y_max = bounds.top\n",
    "pixel_width = transform[0]\n",
    "pixel_height = -transform[4]\n",
    "\n",
    "axes[0][0].imshow(radar_grid, origin='lower')\n",
    "\n",
    "e_d = []\n",
    "e_dx = []\n",
    "e_dy = []\n",
    "\n",
    "for row in range(radar_grid.shape[0]): \n",
    "    y = y_max - (row * pixel_height) + pixel_height / 2\n",
    "    e_dy.append(y)\n",
    "\n",
    "for col in range(radar_grid.shape[0]):\n",
    "\n",
    "    # Calculate middle of cell\n",
    "    x = x_min + (col * pixel_width) + pixel_width / 2\n",
    "    e_dx.append(x)\n",
    "\n",
    "\n",
    "e_dx = np.array(e_dx)\n",
    "e_dy = np.array(e_dy)\n",
    "\n",
    "\n",
    "#Need to interpolate the cml values to the grid in order ot use function\n",
    "\n",
    "second_var_grid = interpolate_scattered_to_grid(\n",
    "   cml_data[:, 0],\n",
    "   cml_data[:, 1],\n",
    "   cml_data[:, 2],\n",
    "   e_dx,\n",
    "   e_dy\n",
    ")\n",
    "\n",
    "numpy_array = np.array(second_var_grid)\n",
    "\n",
    "# Replace NaN values with 0 using nan_to_num\n",
    "converted_array = np.nan_to_num(numpy_array, nan=0.0)\n",
    "\n",
    "# If you need to convert it back to a list of lists\n",
    "second_var_grid = converted_array\n",
    "\n",
    "cml_radar_grid = np.column_stack([radar_grid, second_var_grid])\n",
    "\n",
    "\n",
    "KED_with_radar = UniversalKriging(\n",
    "    x=gauge_data[:, 0],\n",
    "    y=gauge_data[:, 1],\n",
    "    z=gauge_data[:, 2],\n",
    "    variogram_model=variogram_model,\n",
    "    drift_terms=[\"external_Z\"],\n",
    "    external_drift=radar_grid,\n",
    "    external_drift_x=e_dx,\n",
    "    external_drift_y=e_dy,\n",
    "    pseudo_inv=True\n",
    ")\n",
    "\n",
    "KED_with_radar_cml = UniversalKriging(\n",
    "    x=gauge_data[:, 0],\n",
    "    y=gauge_data[:, 1],\n",
    "    z=gauge_data[:, 2],\n",
    "    variogram_model=variogram_model,\n",
    "    drift_terms=['external_Z'],\n",
    "    external_drift=second_var_grid,\n",
    "    external_drift_x=e_dx,\n",
    "    external_drift_y=e_dy,\n",
    "    pseudo_inv=True\n",
    ")\n",
    "\n",
    "UK = UniversalKriging(\n",
    "    gauge_data[:, 0],\n",
    "    gauge_data[:, 1],\n",
    "    gauge_data[:, 2],\n",
    "    variogram_model=variogram_model,\n",
    "    drift_terms=[\"regional_linear\"],\n",
    "    pseudo_inv=True\n",
    ")\n",
    "\n",
    "\n",
    "z,ss = KED_with_radar.execute(\"grid\", gridx, gridy)\n",
    "z2,ss2 = UK.execute(\"grid\", gridx, gridy)\n",
    "z3,ss3 = KED_with_radar_cml.execute(\"grid\", gridx, gridy)\n",
    "\n",
    "axes[0][1].imshow(z2, origin='lower') #Universal kriging\n",
    "axes[0][1].set_title(\"universal kriging\")\n",
    "axes[1][0].imshow(z, origin='lower') #UKriging with external drift\n",
    "axes[1][0].set_title(\"KED\")\n",
    "axes[1][1].imshow(z3, origin='lower') #Kriging with external drift CML + radar\n",
    "axes[1][1].set_title(\"KED + cml\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
