{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c928e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.sampling.main import stratified_spatial_sampling_dual\n",
    "from dataset.weather_graph_dataset import WeatherGraphDatasetWithRadarNew\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from src.raingauge.utils import (\n",
    "    get_station_coordinate_mappings,\n",
    "    load_weather_station_dataset,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from scipy.stats import pearsonr\n",
    "from src.radar.utils import load_radar_dataset\n",
    "from src.visualization.main import pandas_to_geodataframe, visualise_singapore_outline\n",
    "from src.visualization.radar import (\n",
    "    improved_visualise_radar_grid,\n",
    "    visualize_one_radar_image_with_cropping,\n",
    "    visualize_one_radar_image,\n",
    ")\n",
    "from src.visualization.raingauge import visualise_gauge_grid\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "from src.radar.preprocessor import RadarPreprocessor\n",
    "from scipy.spatial import cKDTree\n",
    "from src.miscellaneous import get_straight_distance\n",
    "from models.gnn_radar import HeteroGNN_WithRadar\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Geographic extent of Singapore in longitude and latitude\n",
    "bounds_singapore = {\"left\": 103.6, \"right\": 104.1, \"top\": 1.5, \"bottom\": 1.188}\n",
    "bounds = [0.1, 0.2, 0.5, 1, 2, 4, 7, 10, 20]\n",
    "norm = mpl.colors.BoundaryNorm(boundaries=bounds, ncolors=256, extend=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf40e0",
   "metadata": {},
   "source": [
    "# Preprocess Radar Data\n",
    "\n",
    "## Will find common data between radar and weather station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Radar Image Preprocessing ===\\n\")\n",
    "\n",
    "# Load weather station data\n",
    "# Assuming weather_station_df_pivot is available from your main script\n",
    "# You'll need to load this from your saved data or regenerate it\n",
    "try:\n",
    "    weather_station_data = load_weather_station_dataset(\"weather_station_data.csv\")\n",
    "    weather_station_locations_raw = pd.read_csv(\n",
    "        \"database/weather_stations.csv\"\n",
    "    )\n",
    "\n",
    "    # Filter for general stations\n",
    "    weather_stations_df = weather_station_locations_raw[\n",
    "        weather_station_locations_raw[\"gid\"].isin(weather_station_data)\n",
    "    ].copy()\n",
    "    weather_stations_df = (\n",
    "        weather_stations_df.set_index(\"gid\").loc[weather_station_data].reset_index()\n",
    "    )\n",
    "    weather_station_locations = weather_station_locations_raw.set_index(\"gid\").loc[\n",
    "        weather_station_data\n",
    "    ]\n",
    "\n",
    "    cols = list(weather_stations_df.columns)\n",
    "    cols.remove(\"time_sgt\")\n",
    "    cols.remove(\"gid\")\n",
    "\n",
    "    weather_station_df_pivot = (\n",
    "        pd.pivot(data=weather_stations_df, index=\"time_sgt\", columns=\"gid\", values=cols)\n",
    "        .resample(\"15min\")\n",
    "        .first()\n",
    "    )\n",
    "\n",
    "    print(f\"Loaded weather station data: {weather_stations_df.shape[0]} timestamps\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading weather station data: {e}\")\n",
    "    print(\"Please ensure weather_station_data.csv is available\")\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = RadarPreprocessor(\n",
    "    radar_base_path=\"database/sg_radar_data\",\n",
    "    output_path=\"database/sg_radar_data_cropped\",\n",
    "    weather_station_df=weather_station_df_pivot,\n",
    ")\n",
    "\n",
    "# Step 1: Get all radar files\n",
    "print(\"\\nStep 1: Scanning radar files...\")\n",
    "radar_files = preprocessor.get_all_radar_files()\n",
    "\n",
    "if len(radar_files) == 0:\n",
    "    print(\"No radar files found! Please check the radar_base_path.\")\n",
    "\n",
    "print(f\"Found {len(radar_files)} radar files\")\n",
    "print(f\"Date range: {radar_files[0][0]} to {radar_files[-1][0]}\")\n",
    "\n",
    "# Step 2: Match with weather data\n",
    "print(\"\\nStep 2: Matching with weather station data...\")\n",
    "matched_radar_df, matched_weather_df = preprocessor.match_with_weather_data(radar_files)\n",
    "\n",
    "if len(matched_radar_df) == 0:\n",
    "    raise ValueError(\"No matching timestamps found!\")\n",
    "\n",
    "# Step 3: Process and crop all matched files\n",
    "print(\"\\nStep 3: Cropping radar images to Singapore bounds...\")\n",
    "results_df = preprocessor.process_all_matched_files(matched_radar_df)\n",
    "\n",
    "# Step 4: Save metadata\n",
    "preprocessor.save_metadata(results_df)\n",
    "\n",
    "# Save matched weather dataframe\n",
    "matched_weather_path = preprocessor.output_path / \"matched_weather_station_data.csv\"\n",
    "matched_weather_df.to_csv(matched_weather_path)\n",
    "print(f\"Matched weather station data saved to: {matched_weather_path}\")\n",
    "\n",
    "print(\"\\n=== Preprocessing Complete ===\")\n",
    "print(f\"Cropped radar images saved to: {preprocessor.output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_df = load_radar_dataset(\"sg_radar_data_cropped\", cropped=True)\n",
    "visualize_one_radar_image(radar_df=radar_df, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f5279",
   "metadata": {},
   "source": [
    "# Preprocess Radar Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "dtype = torch.float32\n",
    "radius_km = (\n",
    "    1  # Depends on the radius we want to connect the radar grid to weather stations\n",
    ")\n",
    "\n",
    "# ---- 1) prepare station ID list\n",
    "weather_station_df_pivot[\"rain_rate\"] *= 12\n",
    "station_ids = sorted({col[1] for col in weather_station_df_pivot.columns})\n",
    "\n",
    "# ---- 2) count observations per variable/station\n",
    "station_counts = weather_station_df_pivot.count().reset_index()\n",
    "weather_station_info = pd.pivot(station_counts, index=\"gid\", columns=\"level_0\")\n",
    "\n",
    "# ---- 3) prepare radar features\n",
    "radar_features, grid_coords, grid_shape = preprocessor.prepare_radar_features_temporal(\n",
    "    radar_df, weather_station_df_pivot\n",
    ")\n",
    "\n",
    "# ---- 4) classify rainfall vs general\n",
    "rainfall_station = [\n",
    "    gid for gid, row in weather_station_info.iterrows() if 0 in row.value_counts()\n",
    "]\n",
    "\n",
    "general_station = [\n",
    "    s for s in weather_station_locations.keys() if s not in rainfall_station\n",
    "]\n",
    "\n",
    "# restrict to stations actually present\n",
    "rainfall_station = [s for s in rainfall_station if s in weather_station_info.index]\n",
    "general_station = [s for s in general_station if s in weather_station_info.index]\n",
    "\n",
    "# ---- 5) build coordinate DF (always consistent)\n",
    "print(\"Weather station locations loaded: \", weather_station_locations)\n",
    "loc_df = weather_station_locations[[\"latitude\", \"longitude\"]].copy()\n",
    "\n",
    "\n",
    "# ---- 6) flatten MultiIndex cols\n",
    "df_all = weather_station_info.copy()\n",
    "df_all.columns = [\n",
    "    \"_\".join([str(c) for c in col])  # tuple -> join\n",
    "    if isinstance(col, tuple)\n",
    "    else str(col)  # normal -> stringify\n",
    "    for col in df_all.columns\n",
    "]\n",
    "\n",
    "# split\n",
    "df_rain = df_all.loc[rainfall_station].copy()\n",
    "df_gen = df_all.loc[general_station].copy()\n",
    "\n",
    "# ---- 7) attach coordinates (index matches)\n",
    "df_all = df_all.join(loc_df)\n",
    "df_rain = df_rain.join(loc_df)\n",
    "df_gen = df_gen.join(loc_df)\n",
    "\n",
    "# print(f\"DF ALL: \",df_all.head())\n",
    "# print(f\"DF RAIN: \",df_rain.head())\n",
    "# print(f\"DF GEN: \",df_gen.head())\n",
    "\n",
    "# ---- 8) numpy coordinate arrays\n",
    "rain_coords = df_rain[[\"latitude\", \"longitude\"]].to_numpy()\n",
    "gen_coords = df_gen[[\"latitude\", \"longitude\"]].to_numpy()\n",
    "all_coords = df_all[[\"latitude\", \"longitude\"]].to_numpy()\n",
    "\n",
    "# Convert radius to degrees\n",
    "# 111.0 km per degree is approximate conversion for latitude\n",
    "radius_deg = radius_km / 111.0\n",
    "\n",
    "# ---- 9) Radar to general stations\n",
    "tree_gen = cKDTree(gen_coords)\n",
    "radar_to_gen_list = tree_gen.query_ball_point(grid_coords, r=radius_deg)\n",
    "radar_to_gen_src = []\n",
    "radar_to_gen_dst = []\n",
    "radar_to_gen_distances = []\n",
    "\n",
    "for grid_idx, station_list in enumerate(radar_to_gen_list):\n",
    "    for station_idx in station_list:\n",
    "        # Use the same distance function as station-to-station edges\n",
    "        dist = get_straight_distance(\n",
    "            grid_coords[grid_idx],  # [lat, lon]\n",
    "            gen_coords[station_idx],  # [lat, lon]\n",
    "        )\n",
    "        if dist <= radius_km:\n",
    "            radar_to_gen_src.append(grid_idx)\n",
    "            radar_to_gen_dst.append(station_idx)\n",
    "            radar_to_gen_distances.append([dist])\n",
    "\n",
    "print(f\"Radar to general station connections: {len(radar_to_gen_src)}\")\n",
    "\n",
    "# ---- 10) Radar to rainfall stations\n",
    "tree_rain = cKDTree(rain_coords)\n",
    "radar_to_rain_list = tree_rain.query_ball_point(grid_coords, r=radius_deg)\n",
    "radar_to_rain_src = []\n",
    "radar_to_rain_dst = []\n",
    "radar_to_rain_distances = []\n",
    "\n",
    "for grid_idx, station_list in enumerate(radar_to_rain_list):\n",
    "    for station_idx in station_list:\n",
    "        dist = get_straight_distance(\n",
    "            grid_coords[grid_idx],  # [lat, lon]\n",
    "            rain_coords[station_idx],  # [lat, lon]\n",
    "        )\n",
    "        if dist <= radius_km:\n",
    "            radar_to_rain_src.append(grid_idx)\n",
    "            radar_to_rain_dst.append(station_idx)\n",
    "            radar_to_rain_distances.append([dist])\n",
    "\n",
    "print(f\"Radar to rainfall station connections: {len(radar_to_rain_src)}\")\n",
    "\n",
    "# TODO: Since radar grids are not prediction targets, it's latent features / spatial context providers, not necessary to have radar to radar edges\n",
    "# ---- 11) Radar to radar edges (radius-based, not connectivity-based)\n",
    "# radar_to_radar_edges = preprocessor.create_grid_edges_radius(grid_coords, radius_km)\n",
    "# print(f\"Radar to radar edges: {radar_to_radar_edges.shape[1]} edges created\")\n",
    "# print(f\"First 10 radar-radar edges:\\n{radar_to_radar_edges[:, :10]}\")\n",
    "\n",
    "# ---- 12) Add radar node features to HeteroData\n",
    "data[\"radar_grid\"].x = torch.tensor(radar_features, dtype=dtype)\n",
    "data[\"radar_grid\"].y = torch.tensor(radar_features, dtype=dtype)\n",
    "\n",
    "# ---- 13) Add edges (with empty array handling)\n",
    "# Radar to general stations\n",
    "if len(radar_to_gen_src) > 0:\n",
    "    data[\"radar_grid\", \"radar_to_gen\", \"general_station\"].edge_index = torch.tensor(\n",
    "        np.array([radar_to_gen_src, radar_to_gen_dst]), dtype=torch.long\n",
    "    )\n",
    "    data[\"general_station\", \"gen_to_radar\", \"radar_grid\"].edge_index = torch.tensor(\n",
    "        np.array([radar_to_gen_dst, radar_to_gen_src]), dtype=torch.long\n",
    "    )\n",
    "    # Add distance attributes\n",
    "    data[\"radar_grid\", \"radar_to_gen\", \"general_station\"].edge_attr = torch.tensor(\n",
    "        radar_to_gen_distances, dtype=dtype\n",
    "    )\n",
    "    data[\"general_station\", \"gen_to_radar\", \"radar_grid\"].edge_attr = torch.tensor(\n",
    "        radar_to_gen_distances, dtype=dtype\n",
    "    )\n",
    "else:\n",
    "    print(\"WARNING: No radar to general station edges found within radius\")\n",
    "    data[\"radar_grid\", \"radar_to_gen\", \"general_station\"].edge_index = torch.empty(\n",
    "        (2, 0), dtype=torch.long\n",
    "    )\n",
    "    data[\"general_station\", \"gen_to_radar\", \"radar_grid\"].edge_index = torch.empty(\n",
    "        (2, 0), dtype=torch.long\n",
    "    )\n",
    "    data[\"radar_grid\", \"radar_to_gen\", \"general_station\"].edge_attr = torch.empty(\n",
    "        (0, 1), dtype=dtype\n",
    "    )\n",
    "    data[\"general_station\", \"gen_to_radar\", \"radar_grid\"].edge_attr = torch.empty(\n",
    "        (0, 1), dtype=dtype\n",
    "    )\n",
    "\n",
    "# Radar to rainfall stations\n",
    "if len(radar_to_rain_src) > 0:\n",
    "    data[\"radar_grid\", \"radar_to_rain\", \"rainfall_station\"].edge_index = torch.tensor(\n",
    "        np.array([radar_to_rain_src, radar_to_rain_dst]), dtype=torch.long\n",
    "    )\n",
    "    data[\"rainfall_station\", \"rain_to_radar\", \"radar_grid\"].edge_index = torch.tensor(\n",
    "        np.array([radar_to_rain_dst, radar_to_rain_src]), dtype=torch.long\n",
    "    )\n",
    "    # Add distance attributes\n",
    "    data[\"radar_grid\", \"radar_to_rain\", \"rainfall_station\"].edge_attr = torch.tensor(\n",
    "        radar_to_rain_distances, dtype=dtype\n",
    "    )\n",
    "    data[\"rainfall_station\", \"rain_to_radar\", \"radar_grid\"].edge_attr = torch.tensor(\n",
    "        radar_to_rain_distances, dtype=dtype\n",
    "    )\n",
    "else:\n",
    "    print(\"WARNING: No radar to rainfall station edges found within radius\")\n",
    "    data[\"radar_grid\", \"radar_to_rain\", \"rainfall_station\"].edge_index = torch.empty(\n",
    "        (2, 0), dtype=torch.long\n",
    "    )\n",
    "    data[\"rainfall_station\", \"rain_to_radar\", \"radar_grid\"].edge_index = torch.empty(\n",
    "        (2, 0), dtype=torch.long\n",
    "    )\n",
    "    data[\"radar_grid\", \"radar_to_rain\", \"rainfall_station\"].edge_attr = torch.empty(\n",
    "        (0, 1), dtype=dtype\n",
    "    )\n",
    "    data[\"rainfall_station\", \"rain_to_radar\", \"radar_grid\"].edge_attr = torch.empty(\n",
    "        (0, 1), dtype=dtype\n",
    "    )\n",
    "\n",
    "# ---- 14) Add masks for radar nodes\n",
    "n_radar_nodes = len(grid_coords)\n",
    "data[\"radar_grid\"].train_mask = [1 for _ in range(n_radar_nodes)]\n",
    "data[\"radar_grid\"].val_mask = [1 for _ in range(n_radar_nodes)]\n",
    "data[\"radar_grid\"].test_mask = [1 for _ in range(n_radar_nodes)]\n",
    "\n",
    "# ---- 15) Summary\n",
    "print(\"\\n=== Radar Grid Integration Summary ===\")\n",
    "print(f\"Radar grid nodes: {n_radar_nodes}\")\n",
    "print(f\"Grid shape: {grid_shape[0]} x {grid_shape[1]}\")\n",
    "print(f\"Timesteps: {radar_features.shape[0]}\")\n",
    "print(f\"Radar to general station edges: {len(radar_to_gen_src)}\")\n",
    "print(f\"Radar to rainfall station edges: {len(radar_to_rain_src)}\")\n",
    "print(f\"Station connection radius: {radius_km} km\")\n",
    "print(f\"Grid connection radius: {radius_km} km\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"Radar Features: \", radar_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b30b43",
   "metadata": {},
   "source": [
    "# Preprocess station data.\n",
    "Some stations only contain rainfall information but some stations contain both rainfall and other information.\n",
    "We will split these stations into weather station and general stations \n",
    "\n",
    "Additional info: \n",
    "  Windspeed\n",
    "  Wind Direction\n",
    "  Temperature\n",
    "  Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_data = load_weather_station_dataset('weather_station_data.csv')\n",
    "weather_station_locations = get_station_coordinate_mappings()\n",
    "print(len(weather_station_locations.keys()))\n",
    "print(len(set(weather_station_data['gid'].values)))\n",
    "cols = list(weather_station_data.columns)\n",
    "cols.remove('time_sgt')\n",
    "cols.remove('gid')\n",
    "\n",
    "weather_station_df_pivot = pd.pivot(data=weather_station_data, index='time_sgt', columns='gid', values=cols).resample('15min').first()\n",
    "weather_station_df_pivot['rain_rate'] = weather_station_df_pivot['rain_rate'] * 12\n",
    "weather_station_df_counts = weather_station_df_pivot.count().reset_index()\n",
    "\n",
    "weather_station_info = pd.pivot(data=weather_station_df_counts, index='gid', columns = 'level_0')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "rainfall_station = [row[0] for row in weather_station_info.iterrows() if 0 in row[1].value_counts()]\n",
    "general_station = [s for s in weather_station_locations if s not in rainfall_station]\n",
    "\n",
    "print(rainfall_station)\n",
    "print(general_station)\n",
    "count = 0\n",
    "for row in weather_station_df_pivot['rain_rate'].iterrows():\n",
    "  if np.nansum(row[1].to_numpy()) != 0:\n",
    "    count += 1\n",
    "print(f\"Number of timesteps that contain rain: {count}\")\n",
    "print(f\"Total_timesteps = {weather_station_df_pivot.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e91f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_station_data = {}\n",
    "rainfall_station_data = {}\n",
    "\n",
    "# TODO: Temporal Data Leakage - Filling missing values in the training set using all data including validation or test set is wrong.\n",
    "# Extract and interpolate station data\n",
    "for station in weather_station_df_pivot.columns.get_level_values(1).unique():\n",
    "    station_cols = (\n",
    "        weather_station_df_pivot.xs(station, level=1, axis=1)\n",
    "        .interpolate(method=\"linear\")\n",
    "        .fillna(method=\"ffill\")\n",
    "        .fillna(method=\"bfill\")\n",
    "    )\n",
    "    if station in general_station:\n",
    "        general_station_data[station] = station_cols.values\n",
    "    else:\n",
    "        rainfall_station_data[station] = station_cols.values[:, 0:1]\n",
    "        \n",
    "general_station_temp = [stn for stn in general_station if stn != \"S108\"]\n",
    "general_station = general_station_temp\n",
    "\n",
    "# Prepare features in the correct order\n",
    "general_station_features = []\n",
    "rainfall_station_features = []\n",
    "\n",
    "for station in general_station:\n",
    "    station_feat = general_station_data[station]\n",
    "    general_station_features.append(station_feat)\n",
    "\n",
    "for station in rainfall_station:\n",
    "    station_feat = rainfall_station_data[station]\n",
    "    rainfall_station_features.append(station_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26124db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add station features to HeteroData\n",
    "data[\"general_station\"].x = torch.tensor(\n",
    "    np.array(general_station_features).transpose(1, 0, 2), dtype=dtype\n",
    ")\n",
    "data[\"rainfall_station\"].x = torch.tensor(\n",
    "    np.array(rainfall_station_features).transpose(1, 0, 2), dtype=dtype\n",
    ")\n",
    "\n",
    "# Add station targets\n",
    "data[\"general_station\"].y = torch.tensor(\n",
    "    np.array(general_station_features)[:, :, 0:1].transpose(1, 0, 2), dtype=dtype\n",
    ")\n",
    "data[\"rainfall_station\"].y = torch.tensor(\n",
    "    np.array(rainfall_station_features).transpose(1, 0, 2), dtype=dtype\n",
    ")\n",
    "\n",
    "print(data)\n",
    "print(\"\\n=== Station Features Added ===\")\n",
    "print(f\"General station features shape: {data['general_station'].x.shape}\")\n",
    "print(f\"Rainfall station features shape: {data['rainfall_station'].x.shape}\")\n",
    "\n",
    "# After loading weather_station_df_pivot\n",
    "print(\"--- Station Data Stats ---\")\n",
    "print(weather_station_df_pivot.describe())\n",
    "\n",
    "# After loading radar data\n",
    "print(\"\\n--- Radar Data Stats ---\")\n",
    "print(f\"Radar Min: {radar_features.min()}, Radar Max: {radar_features.max()}, Radar Mean: {radar_features.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853908c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_info = stratified_spatial_sampling_dual(weather_station_locations, seed=1111)\n",
    "print(split_info)\n",
    "\n",
    "data[\"general_station\"].train_mask = [\n",
    "    1 if station in split_info[\"ml\"][\"train\"] else 0 for station in general_station\n",
    "]\n",
    "data[\"general_station\"].val_mask = [\n",
    "    1 if station in split_info[\"ml\"][\"validation\"] else 0 for station in general_station\n",
    "]\n",
    "data[\"general_station\"].test_mask = [\n",
    "    1 if (x == 0 and y == 0) else 0\n",
    "    for x, y in zip(\n",
    "        data[\"general_station\"].train_mask, data[\"general_station\"].val_mask\n",
    "    )\n",
    "]\n",
    "\n",
    "data[\"rainfall_station\"].train_mask = [\n",
    "    1 if station in split_info[\"ml\"][\"train\"] else 0 for station in rainfall_station\n",
    "]\n",
    "data[\"rainfall_station\"].val_mask = [\n",
    "    1 if station in split_info[\"ml\"][\"validation\"] else 0\n",
    "    for station in rainfall_station\n",
    "]\n",
    "data[\"rainfall_station\"].test_mask = [\n",
    "    1 if (x == 0 and y == 0) else 0\n",
    "    for x, y in zip(\n",
    "        data[\"rainfall_station\"].train_mask, data[\"rainfall_station\"].val_mask\n",
    "    )\n",
    "]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae33c3",
   "metadata": {},
   "source": [
    "# Edge generation\n",
    "We consider the location of the stations when performing our edge generation. \n",
    "General station locations and rainfall station locations will be considered the same and we will make a connection across the nodes if required. This will ensure that we can connect both the layers together in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4  # Number of neighbors per node\n",
    "\n",
    "ids = general_station + rainfall_station\n",
    "print(f\"\\nTotal stations for KNN: {len(ids)}\")\n",
    "\n",
    "coordinates = []\n",
    "for id in ids:\n",
    "    coordinates.append(weather_station_locations[id])\n",
    "coords = np.array(coordinates)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=K + 1, algorithm=\"ball_tree\")\n",
    "knn.fit(coords)\n",
    "\n",
    "distances, indices = knn.kneighbors(coords)\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "edges = {\n",
    "    \"rainfall_to_rainfall\": [],\n",
    "    \"rainfall_to_general\": [],\n",
    "    \"general_to_rainfall\": [],\n",
    "    \"general_to_general\": [],\n",
    "}\n",
    "\n",
    "edge_attributes = {\n",
    "    \"rainfall_to_rainfall\": [],\n",
    "    \"rainfall_to_general\": [],\n",
    "    \"general_to_rainfall\": [],\n",
    "    \"general_to_general\": [],\n",
    "}\n",
    "\n",
    "# Add station coordinates for nx plotting\n",
    "for idx, station in enumerate(general_station + rainfall_station):\n",
    "    G.add_node(\n",
    "        idx,\n",
    "        pos=(\n",
    "            weather_station_locations[station][1],\n",
    "            weather_station_locations[station][0],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "color_map = [\"green\" for i in range(len(general_station))] + [\n",
    "    \"red\" for i in range(len(rainfall_station))\n",
    "]\n",
    "\n",
    "# Build edges\n",
    "for idx, row in enumerate(indices):\n",
    "    origin = row[0]\n",
    "\n",
    "    for n in row[1:]:\n",
    "        G.add_edge(origin, n)\n",
    "        if ids[origin] in rainfall_station:\n",
    "            start_id = rainfall_station.index(ids[origin])\n",
    "            if ids[n] in rainfall_station:\n",
    "                end_id = rainfall_station.index(ids[n])\n",
    "                edges[\"rainfall_to_rainfall\"].append([start_id, end_id])\n",
    "                edge_attributes[\"rainfall_to_rainfall\"].append(\n",
    "                    [\n",
    "                        get_straight_distance(\n",
    "                            weather_station_locations[ids[origin]],\n",
    "                            weather_station_locations[ids[n]],\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                end_id = general_station.index(ids[n])\n",
    "                edges[\"rainfall_to_general\"].append([start_id, end_id])\n",
    "                edge_attributes[\"rainfall_to_general\"].append(\n",
    "                    [\n",
    "                        get_straight_distance(\n",
    "                            weather_station_locations[ids[origin]],\n",
    "                            weather_station_locations[ids[n]],\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "        else:\n",
    "            start_id = general_station.index(ids[origin])\n",
    "            if ids[n] in rainfall_station:\n",
    "                end_id = rainfall_station.index(ids[n])\n",
    "                edges[\"general_to_rainfall\"].append([start_id, end_id])\n",
    "                edge_attributes[\"general_to_rainfall\"].append(\n",
    "                    [\n",
    "                        get_straight_distance(\n",
    "                            weather_station_locations[ids[origin]],\n",
    "                            weather_station_locations[ids[n]],\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                end_id = general_station.index(ids[n])\n",
    "                edges[\"general_to_general\"].append([start_id, end_id])\n",
    "                edge_attributes[\"general_to_general\"].append(\n",
    "                    [\n",
    "                        get_straight_distance(\n",
    "                            weather_station_locations[ids[origin]],\n",
    "                            weather_station_locations[ids[n]],\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "print(f\"\\nGraph info: {G}\")\n",
    "print(f\"Connected components: {len(list(nx.connected_components(G)))}\")\n",
    "nx.draw(G, nx.get_node_attributes(G, 'pos'), node_color = color_map, with_labels=True, font_weight='bold')\n",
    "\n",
    "# Convert edge lists to proper format\n",
    "for key, val in edges.items():\n",
    "    xarr = []\n",
    "    yarr = []\n",
    "    for x, y in val:\n",
    "        xarr.append(x)\n",
    "        yarr.append(y)\n",
    "    edges[key] = [xarr, yarr]\n",
    "\n",
    "# Add station-to-station edges\n",
    "data[\"general_station\", \"gen_to_rain\", \"rainfall_station\"].edge_index = torch.tensor(\n",
    "    edges[\"general_to_rainfall\"], dtype=torch.long\n",
    ")\n",
    "data[\"rainfall_station\", \"rain_to_gen\", \"general_station\"].edge_index = torch.tensor(\n",
    "    edges[\"rainfall_to_general\"], dtype=torch.long\n",
    ")\n",
    "data[\"general_station\", \"gen_to_gen\", \"general_station\"].edge_index = torch.tensor(\n",
    "    edges[\"general_to_general\"], dtype=torch.long\n",
    ")\n",
    "data[\"rainfall_station\", \"rain_to_rain\", \"rainfall_station\"].edge_index = torch.tensor(\n",
    "    edges[\"rainfall_to_rainfall\"], dtype=torch.long\n",
    ")\n",
    "\n",
    "# Add edge attributes\n",
    "data[\"general_station\", \"gen_to_rain\", \"rainfall_station\"].edge_attr = torch.tensor(\n",
    "    edge_attributes[\"general_to_rainfall\"], dtype=dtype\n",
    ")\n",
    "data[\"rainfall_station\", \"rain_to_gen\", \"general_station\"].edge_attr = torch.tensor(\n",
    "    edge_attributes[\"rainfall_to_general\"], dtype=dtype\n",
    ")\n",
    "data[\"general_station\", \"gen_to_gen\", \"general_station\"].edge_attr = torch.tensor(\n",
    "    edge_attributes[\"general_to_general\"], dtype=dtype\n",
    ")\n",
    "data[\"rainfall_station\", \"rain_to_rain\", \"rainfall_station\"].edge_attr = torch.tensor(\n",
    "    edge_attributes[\"rainfall_to_rainfall\"], dtype=dtype\n",
    ")\n",
    "\n",
    "print(\"\\n=== Station-to-Station Edges Added ===\")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL HETERODATA STRUCTURE\")\n",
    "print(\"=\" * 60)\n",
    "print(data)\n",
    "print(\"\\nNode types:\", data.node_types)\n",
    "print(\"Edge types:\", data.edge_types)\n",
    "\n",
    "print(\"\\n--- Feature Shapes ---\")\n",
    "print(f\"General stations: {data['general_station'].x.shape}\")\n",
    "print(f\"Rainfall stations: {data['rainfall_station'].x.shape}\")\n",
    "print(f\"Radar grid: {data['radar_grid'].x.shape}\")\n",
    "\n",
    "print(\"\\n--- Edge Counts ---\")\n",
    "for edge_type in data.edge_types:\n",
    "    edge_count = data[edge_type].edge_index.shape[1]\n",
    "    print(f\"{edge_type}: {edge_count} edges\")\n",
    "\n",
    "print(\"\\n--- Mask Counts ---\")\n",
    "print(f\"General train: {sum(data['general_station'].train_mask)}\")\n",
    "print(f\"General val: {sum(data['general_station'].val_mask)}\")\n",
    "print(f\"General test: {sum(data['general_station'].test_mask)}\")\n",
    "print(f\"Rainfall train: {sum(data['rainfall_station'].train_mask)}\")\n",
    "print(f\"Rainfall val: {sum(data['rainfall_station'].val_mask)}\")\n",
    "print(f\"Rainfall test: {sum(data['rainfall_station'].test_mask)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(edge_attributes[\"rainfall_to_rainfall\"]))\n",
    "\n",
    "# Process edge indices\n",
    "print(data)\n",
    "print(data.edge_types)\n",
    "\n",
    "print(data[\"general_station\", \"gen_to_rain\", \"rainfall_station\"].edge_attr)\n",
    "print(data[\"rainfall_station\", \"rain_to_gen\", \"general_station\"].edge_index)\n",
    "print(data[\"general_station\", \"gen_to_gen\", \"general_station\"].edge_index)\n",
    "print(\n",
    "    len(\n",
    "        set(\n",
    "            data[\"rainfall_station\", \"rain_to_rain\", \"rainfall_station\"]\n",
    "            .edge_index.detach()\n",
    "            .numpy()[0]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(data.has_isolated_nodes())\n",
    "print(data.has_self_loops())\n",
    "print(data.is_undirected())\n",
    "\n",
    "print(data[\"general_station\", \"gen_to_rain\", \"rainfall_station\"][\"edge_index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f959a81",
   "metadata": {},
   "source": [
    "# Creating the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131359f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeteroGNN_WithRadar(hidden_channels=8, out_channels=1, num_layers=5)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data, dataloader, optimizer, device, verbose=False, log_file=\"training_radar_debug.log\"):\n",
    "    \"\"\"Training loop with radar data.\"\"\"\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    charge_bar = tqdm.tqdm(dataloader, desc='training')\n",
    "\n",
    "    # Setup logging if verbose\n",
    "    if verbose:\n",
    "        logger = logging.getLogger(\"train_debug\")\n",
    "        logger.setLevel(logging.INFO)\n",
    "        if not logger.handlers:                           # avoid adding twice\n",
    "            fh = logging.FileHandler(\"training_radar_debug.log\", mode=\"a\")\n",
    "            fh.setFormatter(logging.Formatter(\"%(asctime)s - %(message)s\"))\n",
    "            logger.addHandler(fh)\n",
    "        # logging.basicConfig(\n",
    "        #     filename=log_file,\n",
    "        #     level=logging.INFO,\n",
    "        #     format=\"%(asctime)s - %(message)s\",\n",
    "        #     filemode='w'\n",
    "        # )\n",
    "        logger.info(f\"=== Training Epoch Debug Log Started at {datetime.now()} ===\")\n",
    "\n",
    "    for batch in charge_bar:\n",
    "      # reset gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      edge_index_dict = batch[\"edge_index_dict\"]\n",
    "      edge_attribute_dict = batch[\"edge_attr_dict\"]\n",
    "\n",
    "      for i in range(batch['gen_x'].shape[0]):\n",
    "\n",
    "        train_metastation_mask = torch.tensor(batch['metastation_mask'], dtype=torch.bool).to(device)\n",
    "        train_rainfallstation_mask = torch.tensor(batch['rainfallstation_mask'], dtype=torch.bool).to(device)\n",
    "        step_loss = []\n",
    "\n",
    "        training_metastation_indices = train_metastation_mask.nonzero(as_tuple=False)\n",
    "        training_rainfallstation_indices = train_rainfallstation_mask.nonzero(as_tuple=False)\n",
    "        gen_x = batch['gen_x']  # [batch_size, num_gen_nodes, gen_features]\n",
    "        rain_x = batch['rain_x']  # [batch_size, num_rain_nodes, rain_features]\n",
    "        radar_x = batch[\"radar_x\"]\n",
    "        gen_y = batch['gen_y']\n",
    "        rain_y = batch['rain_y']\n",
    "\n",
    "        #Start by indiviually masking metastations\n",
    "        for idx in training_metastation_indices:\n",
    "            gen_x_masked=gen_x[i].clone()\n",
    "            rain_x_masked=rain_x[i].clone()\n",
    "    \n",
    "            gen_x_masked[~train_metastation_mask.bool()] = 0\n",
    "            rain_x_masked[~train_rainfallstation_mask.bool()] = 0\n",
    "            gen_x_masked[idx, 0] = 0 #mask only the first value which corresponds to the rainfall value\n",
    "\n",
    "            x_dict = {\n",
    "                \"general_station\": gen_x_masked,\n",
    "                \"rainfall_station\": rain_x_masked,\n",
    "                \"radar_grid\": radar_x[i],\n",
    "            }\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_dict, edge_index_dict, edge_attribute_dict)\n",
    "\n",
    "            # Model prediction\n",
    "            gen_predictions = out['general_station'][idx]\n",
    "            gen_actual = gen_y[i][idx]\n",
    "\n",
    "            training_loss = F.mse_loss(gen_predictions, gen_actual) \n",
    "            if verbose:\n",
    "                log_msg = f\"\"\"\n",
    "                    --- DEBUG STATS (General Station) ---\n",
    "                    --- INPUT FEATURES ---\n",
    "                    Radar grid features:     Min={x_dict['radar_grid'].min():.2f}, Max={x_dict['radar_grid'].max():.2f}, Mean={x_dict['radar_grid'].mean():.2f}\n",
    "                    General station features: Min={x_dict['general_station'].min():.2f}, Max={x_dict['general_station'].max():.2f}, Mean={x_dict['general_station'].mean():.2f}\n",
    "\n",
    "                    --- MODEL PREDICTIONS (raw) ---\n",
    "                    Pred (gen) tensor:    Min={out['general_station'].min():.2f}, Max={out['general_station'].max():.2f}, Mean={out['general_station'].mean():.2f}\n",
    "\n",
    "                    --- GROUND TRUTH ---\n",
    "                    Truth (gen) tensor:   Min={gen_y[i].min():.2f}, Max={gen_y[i].max():.2f}, Mean={gen_y[i].mean():.2f}\n",
    "\n",
    "                    --- LOSS ---\n",
    "                    Loss for this sample: {training_loss.item():.2f}\n",
    "                    -------------------------------------------------\n",
    "                    \"\"\"\n",
    "                logger.info(log_msg)\n",
    "            step_loss.append(training_loss)\n",
    "\n",
    "        #Indiviually mask rain stations\n",
    "        for idx in training_rainfallstation_indices:\n",
    "            gen_x_masked=gen_x[i].clone()\n",
    "            rain_x_masked=rain_x[i].clone()\n",
    "    \n",
    "            #Mask stations that are not training stations\n",
    "            gen_x_masked[~train_metastation_mask.bool()] = 0\n",
    "            rain_x_masked[~train_rainfallstation_mask.bool()] = 0\n",
    "            #Mask the selected rainfall station\n",
    "            rain_x_masked[idx, 0] = 0\n",
    "\n",
    "            x_dict = {\n",
    "                'general_station': gen_x_masked,\n",
    "                'rainfall_station': rain_x_masked,\n",
    "                \"radar_grid\": radar_x[i],\n",
    "            }\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_dict, edge_index_dict, edge_attribute_dict)\n",
    "\n",
    "            # Model prediction\n",
    "            rain_predictions = out['rainfall_station'][idx]\n",
    "            rainfall_actual = rain_y[i][idx]\n",
    "\n",
    "            training_loss = F.mse_loss(rain_predictions, rainfall_actual)\n",
    "            if verbose:\n",
    "                log_msg = f\"\"\"\n",
    "                    --- DEBUG STATS (Rainfall Station) ---\n",
    "                    --- INPUT FEATURES ---\n",
    "                    Radar grid features:     Min={x_dict['radar_grid'].min():.2f}, Max={x_dict['radar_grid'].max():.2f}, Mean={x_dict['radar_grid'].mean():.2f}\n",
    "                    Rainfall station features: Min={x_dict['rainfall_station'].min():.2f}, Max={x_dict['rainfall_station'].max():.2f}, Mean={x_dict['rainfall_station'].mean():.2f}\n",
    "\n",
    "                    --- MODEL PREDICTIONS (raw) ---\n",
    "                    Pred (rain) tensor:   Min={out['rainfall_station'].min():.2f}, Max={out['rainfall_station'].max():.2f}, Mean={out['rainfall_station'].mean():.2f}\n",
    "\n",
    "                    --- GROUND TRUTH ---\n",
    "                    Truth (rain) tensor:  Min={rain_y[i].min():.2f}, Max={rain_y[i].max():.2f}, Mean={rain_y[i].mean():.2f}\n",
    "\n",
    "                    --- LOSS ---\n",
    "                    Loss for this sample: {training_loss.item():.2f}\n",
    "                    -------------------------------------------------\n",
    "                    \"\"\"\n",
    "                logger.info(log_msg)\n",
    "            step_loss.append(training_loss)\n",
    "        \n",
    "        loss = torch.stack(step_loss).mean()\n",
    "        losses.append(loss.detach())\n",
    "\n",
    "        #backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    losses = torch.stack(losses).mean().item()\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data, dataloader, device):\n",
    "    \"\"\"Validation loop with radar data.\"\"\"\n",
    "    model.eval()  # Set to eval mode\n",
    "    total_validation_loss = 0\n",
    "\n",
    "    # Prepare masks\n",
    "    val_gen_mask = torch.tensor(data[\"general_station\"].val_mask, dtype=torch.bool).to(\n",
    "        device\n",
    "    )\n",
    "    val_rain_mask = torch.tensor(\n",
    "        data[\"rainfall_station\"].val_mask, dtype=torch.bool\n",
    "    ).to(device)\n",
    "    test_gen_mask = torch.tensor(\n",
    "        data[\"general_station\"].test_mask, dtype=torch.bool\n",
    "    ).to(device)\n",
    "    test_rain_mask = torch.tensor(\n",
    "        data[\"rainfall_station\"].test_mask, dtype=torch.bool\n",
    "    ).to(device)\n",
    "    train_gen_mask = torch.tensor(\n",
    "        data[\"general_station\"].train_mask, dtype=torch.bool\n",
    "    ).to(device)\n",
    "    train_rain_mask = torch.tensor(\n",
    "        data[\"rainfall_station\"].train_mask, dtype=torch.bool\n",
    "    ).to(device)\n",
    "\n",
    "    # Move edge data to device\n",
    "    edge_index_dict = {key: val.to(device) for key, val in data.edge_index_dict.items()}\n",
    "    edge_attr_dict = {key: val.to(device) for key, val in data.edge_attr_dict.items()}\n",
    "\n",
    "    with torch.no_grad():  # No gradients during validation\n",
    "        for batch in tqdm.tqdm(dataloader, desc=\"Validation\"):\n",
    "            gen_x = batch[\"gen_x\"].to(device)\n",
    "            rain_x = batch[\"rain_x\"].to(device)\n",
    "            radar_x = batch[\"radar_x\"].to(device)  # Add radar\n",
    "            gen_y = batch[\"gen_y\"].to(device)\n",
    "            rain_y = batch[\"rain_y\"].to(device)\n",
    "\n",
    "            batch_size = gen_x.shape[0]\n",
    "            batch_loss = 0\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                # Mask train and test stations for validation\n",
    "                gen_x_masked = gen_x[i].clone()\n",
    "                rain_x_masked = rain_x[i].clone()\n",
    "\n",
    "                gen_x_masked[test_gen_mask] = 0\n",
    "                rain_x_masked[test_rain_mask] = 0\n",
    "                gen_x_masked[train_gen_mask] = 0\n",
    "                rain_x_masked[train_rain_mask] = 0\n",
    "\n",
    "                # Create input dictionary with radar data\n",
    "                x_dict = {\n",
    "                    \"general_station\": gen_x_masked,\n",
    "                    \"rainfall_station\": rain_x_masked,\n",
    "                    \"radar_grid\": radar_x[i],  # Radar is NOT masked\n",
    "                }\n",
    "\n",
    "                out = model(x_dict, edge_index_dict, edge_attr_dict)\n",
    "\n",
    "                # Calculate loss only on validation stations\n",
    "                gen_predictions = out[\"general_station\"][val_gen_mask]\n",
    "                rain_predictions = out[\"rainfall_station\"][val_rain_mask]\n",
    "\n",
    "                validation_loss = F.mse_loss(\n",
    "                    gen_predictions, gen_y[i][val_gen_mask]\n",
    "                ) + F.mse_loss(rain_predictions, rain_y[i][val_rain_mask])\n",
    "\n",
    "                batch_loss += validation_loss.item()\n",
    "\n",
    "            total_validation_loss += batch_loss / batch_size\n",
    "\n",
    "    return total_validation_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c428c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "train_dataset = WeatherGraphDatasetWithRadarNew(data, mode=\"train\")\n",
    "val_dataset = WeatherGraphDatasetWithRadarNew(data, mode=\"val\")\n",
    "\n",
    "\n",
    "def collate_temporal_graphs(batch):\n",
    "  gen_x = torch.stack([item['gen_x'] for item in batch])\n",
    "  rain_x = torch.stack([item['rain_x'] for item in batch])\n",
    "  radar_x= torch.stack([item[\"radar_x\"]for item in batch])\n",
    "  gen_y = torch.stack([item['gen_y'] for item in batch])\n",
    "  rain_y = torch.stack([item['rain_y'] for item in batch])\n",
    "\n",
    "  metastation_mask = batch[0]['metastation_mask']\n",
    "  rainfallstation_mask = batch[0]['rainfallstation_mask']\n",
    "  edge_index_dict = batch[0]['edge_index_dict']\n",
    "  edge_attribute_dict = batch[0]['edge_attr_dict']\n",
    "\n",
    "  return {\n",
    "      'gen_x': gen_x,\n",
    "      'rain_x': rain_x,\n",
    "      \"radar_x\": radar_x,\n",
    "      'gen_y': gen_y,\n",
    "      'rain_y': rain_y,\n",
    "      'metastation_mask': metastation_mask,\n",
    "      'rainfallstation_mask': rainfallstation_mask,\n",
    "      'edge_index_dict': edge_index_dict,\n",
    "      'edge_attr_dict': edge_attribute_dict\n",
    "  }\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_temporal_graphs,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_temporal_graphs,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "training_loss_arr = []\n",
    "validation_loss_arr = []\n",
    "early = 0\n",
    "mini = 1000\n",
    "stopping_condition = 3\n",
    "epochs = 0\n",
    "\n",
    "training_start = time.time()\n",
    "for i in range(20):\n",
    "    print(f\"-----EPOCH: {i + 1}-----\")\n",
    "    train_loss = train_epoch(model, data, train_loader, optimizer, device, verbose=True)\n",
    "    validation_loss = validate(model, data, val_loader, device)\n",
    "    training_loss_arr.append(train_loss)\n",
    "    validation_loss_arr.append(validation_loss)\n",
    "    if mini >= validation_loss:\n",
    "        mini = validation_loss\n",
    "        early = 0\n",
    "    else:\n",
    "        early += 1\n",
    "    epochs += 1\n",
    "    if early >= stopping_condition:\n",
    "        print(\"Early stop loss\")\n",
    "        break\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "\n",
    "training_end = time.time()\n",
    "\n",
    "print(f\"Training took {training_end - training_start} seconds over {epochs} epochs\")\n",
    "plt.plot(training_loss_arr, label=\"training_loss\", color=\"blue\")\n",
    "plt.plot(validation_loss_arr, label=\"validation_loss\", color=\"red\")\n",
    "plt.legend()\n",
    "\n",
    "torch.save(model.state_dict(), \"weights/weather_gnn_best.pth\")\n",
    "print(\"âœ… model weights saved to weather_gnn_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fdc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(iter(val_loader))[\"gen_x\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623fbdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(param.numel() for param in model.parameters())\n",
    "print(total_params)\n",
    "print(list(param for param in model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35259636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data, device, collate_fn):\n",
    "    model.eval()\n",
    "    total_rmse = 0\n",
    "\n",
    "    plot_preds = np.array([])\n",
    "    plot_actual = np.array([])\n",
    "\n",
    "    test_dataset = WeatherGraphDatasetWithRadarNew(data, mode=\"test\") \n",
    "\n",
    "    val_gen_mask = torch.tensor(\n",
    "        data[\"general_station\"].val_mask, dtype=torch.bool\n",
    "    ).to(device)\n",
    "    val_rain_mask = torch.tensor(\n",
    "        data[\"rainfall_station\"].val_mask, dtype=torch.bool  # Bug fixed here\n",
    "    ).to(device)\n",
    "    test_gen_mask = torch.tensor(\n",
    "        data[\"general_station\"].test_mask, dtype=torch.bool\n",
    "    ).to(device)\n",
    "    test_rain_mask = torch.tensor(\n",
    "        data[\"rainfall_station\"].test_mask, dtype=torch.bool\n",
    "    ).to(device)\n",
    "\n",
    "    edge_index_dict = {key: val.to(device) for key, val in data.edge_index_dict.items()}\n",
    "    edge_attr_dict = {key: val.to(device) for key, val in data.edge_attr_dict.items()}\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn  # Use the passed-in collate_fn\n",
    "    )\n",
    "\n",
    "    count = 0\n",
    "    printed_stats = False  # Flag to print stats only once\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(test_dataloader, desc=\"Testing\"):\n",
    "            gen_x = batch[\"gen_x\"].to(device)\n",
    "            rain_x = batch[\"rain_x\"].to(device)\n",
    "            radar_x = batch[\"radar_x\"].to(device)\n",
    "            gen_y = batch[\"gen_y\"].to(device)\n",
    "            rain_y = batch[\"rain_y\"].to(device)\n",
    "\n",
    "            batch_size = gen_x.shape[0]\n",
    "            batch_rmse = 0\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                gen_x_masked = gen_x[i].clone()\n",
    "                rain_x_masked = rain_x[i].clone()\n",
    "\n",
    "                # Mask out all non-training nodes, as done in training\n",
    "                gen_x_masked[val_gen_mask] = 0\n",
    "                rain_x_masked[val_rain_mask] = 0\n",
    "                gen_x_masked[test_gen_mask] = 0\n",
    "                rain_x_masked[test_rain_mask] = 0\n",
    "                \n",
    "                x_dict = {\n",
    "                    \"general_station\": gen_x_masked,\n",
    "                    \"rainfall_station\": rain_x_masked,\n",
    "                    \"radar_grid\": radar_x[i],\n",
    "                }\n",
    "\n",
    "                out = model(x_dict, edge_index_dict, edge_attr_dict)\n",
    "\n",
    "                # 3. Calculate predictions and targets on TEST nodes\n",
    "                gen_predictions = out[\"general_station\"][test_gen_mask]\n",
    "                rain_predictions = out[\"rainfall_station\"][test_rain_mask]\n",
    "\n",
    "                gen_targets = gen_y[i][test_gen_mask]\n",
    "                rain_targets = rain_y[i][test_rain_mask]\n",
    "\n",
    "                # ==== DEBUGGING PRINT BLOCK ====\n",
    "                if not printed_stats and i == 0:\n",
    "                    print(\"\\n--- DEBUG STATS (First Sample of Test Set) ---\")\n",
    "                    \n",
    "                    print(\"\\n--- INPUT FEATURES (Masked) ---\")\n",
    "                    print(f\"Radar grid features:     Min={x_dict['radar_grid'].min():.2f}, Max={x_dict['radar_grid'].max():.2f}, Mean={x_dict['radar_grid'].mean():.2f}\")\n",
    "                    print(f\"General station features:  Min={x_dict['general_station'].min():.2f}, Max={x_dict['general_station'].max():.2f}, Mean={x_dict['general_station'].mean():.2f}\")\n",
    "                    \n",
    "                    print(\"\\n--- MODEL PREDICTIONS (for TEST nodes) ---\")\n",
    "                    if gen_predictions.numel() > 0:\n",
    "                        print(f\"Pred (gen) tensor:    Min={gen_predictions.min():.2f}, Max={gen_predictions.max():.2f}, Mean={gen_predictions.mean():.2f}\")\n",
    "                    else:\n",
    "                        print(\"Pred (gen) tensor is empty for this batch.\")\n",
    "\n",
    "                    if rain_predictions.numel() > 0:\n",
    "                        print(f\"Pred (rain) tensor:   Min={rain_predictions.min():.2f}, Max={rain_predictions.max():.2f}, Mean={rain_predictions.mean():.2f}\")\n",
    "                    else:\n",
    "                        print(\"Pred (rain) tensor is empty for this batch.\")\n",
    "\n",
    "\n",
    "                    print(\"\\n--- GROUND TRUTH (for TEST nodes) ---\")\n",
    "                    if gen_targets.numel() > 0:\n",
    "                        print(f\"Truth (gen) tensor:    Min={gen_targets.min():.2f}, Max={gen_targets.max():.2f}, Mean={gen_targets.mean():.2f}\")\n",
    "                    else:\n",
    "                        print(\"Truth (gen) tensor is empty for this batch.\")\n",
    "\n",
    "                    if rain_targets.numel() > 0:\n",
    "                        print(f\"Truth (rain) tensor:   Min={rain_targets.min():.2f}, Max={rain_targets.max():.2f}, Mean={rain_targets.mean():.2f}\")\n",
    "                    else:\n",
    "                        print(\"Truth (rain) tensor is empty for this batch.\")\n",
    "                    \n",
    "                    printed_stats = True\n",
    "                # ===============================\n",
    "\n",
    "                plot_preds = np.concatenate(\n",
    "                    (\n",
    "                        plot_preds,\n",
    "                        gen_predictions.cpu().detach().numpy().flatten(),\n",
    "                        rain_predictions.cpu().detach().numpy().flatten(),\n",
    "                    )\n",
    "                )\n",
    "                plot_actual = np.concatenate(\n",
    "                    (\n",
    "                        plot_actual,\n",
    "                        gen_targets.cpu().detach().numpy().flatten(),\n",
    "                        rain_targets.cpu().detach().numpy().flatten(),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                gen_MSE_arr = (gen_predictions - gen_targets) ** 2\n",
    "                rain_MSE_arr = (rain_predictions - rain_targets) ** 2\n",
    "\n",
    "                all_squared_errors = torch.cat([gen_MSE_arr, rain_MSE_arr])\n",
    "                test_rmse = torch.sqrt(torch.mean(all_squared_errors))\n",
    "\n",
    "                batch_rmse += test_rmse.item()\n",
    "                count += 1\n",
    "\n",
    "            total_rmse += batch_rmse\n",
    "\n",
    "    # --- Plotting and Final Metrics ---\n",
    "    plt.figure(figsize=(8, 8)) # Make plot bigger\n",
    "    plt.scatter(x=plot_actual, y=plot_preds, alpha=0.5) # Add alpha\n",
    "    plot_bound = max(\n",
    "        np.nanmax(plot_actual).astype(int), np.nanmax(plot_preds).astype(int)\n",
    "    )\n",
    "    plt.plot(np.linspace(0, plot_bound, 100), np.linspace(0, plot_bound, 100), 'r--') # Add red dashed line\n",
    "    plt.xlabel(\"Actual Rainfall (Test Stations)\")\n",
    "    plt.ylabel(\"Predicted Rainfall (Test Stations)\")\n",
    "    plt.title(\"Test Set Performance\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"radar_new_test_scatter_plot.png\")\n",
    "    plt.close() # Close plot to prevent double display\n",
    "    print(\"Saved test scatter plot to 'test_scatter_plot.png'\")\n",
    "\n",
    "\n",
    "    mask = ~np.isnan(plot_actual) & ~np.isnan(plot_preds) # Also check for NaNs in preds\n",
    "    pearson_r_global, pearson_p_global = pearsonr(plot_actual[mask], plot_preds[mask])\n",
    "\n",
    "    print(f\"Pearson correlation (Test Stations): {pearson_r_global}\")\n",
    "    \n",
    "    final_rmse = total_rmse / count\n",
    "    print(f\"Final Test RMSE (Test Stations): {final_rmse}\")\n",
    "    return final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff01a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = test_model(model, data, device, collate_temporal_graphs)\n",
    "print(f\"TEST RMSE: {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606be2d",
   "metadata": {},
   "source": [
    "# Visualisation of output\n",
    "Test event will be 02-05-2025 0415 to 0615\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0dc8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_one_event(test_event_data, radar_features_event, do_plot=True):\n",
    "    \"\"\"\n",
    "    Prepare a single example from `test_event_data` (a pandas slice like\n",
    "    weather_station_df_pivot.iloc[593:602]) and run the model for inference.\n",
    "\n",
    "    This function returns:\n",
    "      gen_out: numpy array of predicted general_station outputs (shape: [num_gen_nodes, out_features])\n",
    "      rain_out: numpy array of predicted rainfall_station outputs (shape: [num_rain_nodes, out_features])\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # clone template (so we keep masks/edge_index/order)\n",
    "    test_data = data.clone()\n",
    "\n",
    "    # --- collect station-wise time-series just like you had before ---\n",
    "    test_general_station_data = {}\n",
    "    test_rainfall_station_data = {}\n",
    "\n",
    "    for station in test_event_data.columns.get_level_values(1).unique():\n",
    "        station_cols = (\n",
    "            test_event_data.xs(station, level=1, axis=1)\n",
    "            .interpolate(method=\"linear\")\n",
    "            .fillna(method=\"ffill\")\n",
    "            .fillna(method=\"bfill\")\n",
    "        )\n",
    "        if station in general_station:\n",
    "            test_general_station_data[station] = (\n",
    "                station_cols.values\n",
    "            )  # shape [T, gen_feat]\n",
    "        else:\n",
    "            test_rainfall_station_data[station] = station_cols.values[\n",
    "                :, 0:1\n",
    "            ]  # [T, rain_feat=1]\n",
    "\n",
    "    # Build arrays in the correct node ordering\n",
    "    gen_feats_list = []\n",
    "    rain_feats_list = []\n",
    "\n",
    "    for station in general_station:\n",
    "        gen_feats_list.append(\n",
    "            test_general_station_data[station]\n",
    "        )  # each item: [T, gen_feat_per_t]\n",
    "    for station in rainfall_station:\n",
    "        rain_feats_list.append(\n",
    "            test_rainfall_station_data[station]\n",
    "        )  # each item: [T, rain_feat_per_t]\n",
    "\n",
    "    # Convert to numpy arrays and get shapes\n",
    "    # After np.array(gen_feats_list) => shape [num_gen_nodes, T, gen_feat_per_t]\n",
    "    gen_arr = np.array(gen_feats_list)  # [N_gen, T, Fg]\n",
    "    rain_arr = np.array(rain_feats_list)  # [N_rain, T, Fr]\n",
    "\n",
    "    # --- Convert to the 2-D node-feature format the model expects ---\n",
    "    # There are different sensible choices here:\n",
    "    #  - take last timestep: arr[:, -1, :] -> [N, F]\n",
    "    #  - flatten the time axis into the feature axis: arr.reshape(N, T*F)\n",
    "    # The training/test collate you used produces per-node features (no time dim).\n",
    "    # To match that, we flatten time into features (preserves the whole window).\n",
    "    def flatten_time_axis(arr):\n",
    "        # arr: [N, T, F]\n",
    "        N, T, F = arr.shape\n",
    "        return arr.reshape(N, T * F)  # [N, T*F]\n",
    "\n",
    "    gen_node_feats = gen_arr[:, -1, :].astype(np.float32)\n",
    "    rain_node_feats = rain_arr[:, -1, :].astype(np.float32)  # [N, F]\n",
    "    radar_node_feats = radar_features_event[-1].float()  # [N_radar, F]\n",
    "\n",
    "    # Convert to torch tensors (2-D per node type) and move to device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    x_dict = {\n",
    "        \"general_station\": torch.tensor(\n",
    "            gen_node_feats, dtype=torch.float, device=device\n",
    "        ),\n",
    "        \"rainfall_station\": torch.tensor(\n",
    "            rain_node_feats, dtype=torch.float, device=device\n",
    "        ),\n",
    "        \"radar_grid\": torch.tensor(radar_node_feats, dtype=torch.float, device=device),\n",
    "    }\n",
    "\n",
    "    # Move edge structures to device (the same ones you used in test_model)\n",
    "    edge_index_dict = {k: v.to(device) for k, v in data.edge_index_dict.items()}\n",
    "    edge_attr_dict = {k: v.to(device) for k, v in data.edge_attr_dict.items()}\n",
    "\n",
    "    # Run model\n",
    "    with torch.no_grad():\n",
    "        out = model(x_dict, edge_index_dict, edge_attr_dict)\n",
    "\n",
    "    # out[...] are torch tensors shaped like [num_nodes, out_features] (depending on your model head)\n",
    "    gen_out = out[\"general_station\"].cpu().numpy()\n",
    "    rain_out = out[\"rainfall_station\"].cpu().numpy()\n",
    "\n",
    "    return gen_out, rain_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c852b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_event_data = weather_station_df_pivot.iloc[593:602]  # your 9 timestamps\n",
    "radar_features_event = data['radar_grid'].x[593:602]\n",
    "gen_out, rain_out = visualize_one_event(test_event_data, radar_features_event)\n",
    "out_np = np.concatenate([gen_out, rain_out], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca57f6f",
   "metadata": {},
   "source": [
    "# Visualise rain on radar grid\n",
    "Hard coded to plot only consequitive 9 timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_np / 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843bf48",
   "metadata": {},
   "source": [
    "# Visualize Radar Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_df = load_radar_dataset(\"sg_radar_data\")\n",
    "\n",
    "visualize_one_radar_image(radar_df=radar_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    3, 3, figsize=(15, 12), subplot_kw={\"projection\": ccrs.PlateCarree()}\n",
    ")\n",
    "\n",
    "out_np = out_np / 12\n",
    "for idx, timestamp in enumerate(out_np):\n",
    "    output = {}\n",
    "    count = 0\n",
    "\n",
    "    for stn in general_station:\n",
    "        output[stn] = float(timestamp[count])\n",
    "        count += 1\n",
    "    for stn in rainfall_station:\n",
    "        output[stn] = float(timestamp[count])\n",
    "        count += 1\n",
    "    axi = ax[idx // 3][idx % 3]\n",
    "    node_df = pd.Series(output)\n",
    "    node_df = pandas_to_geodataframe(node_df)\n",
    "    visualise_gauge_grid(node_df=node_df, ax=axi)\n",
    "    improved_visualise_radar_grid(\n",
    "        radar_df.iloc[idx], ax=axi, zoom=bounds_singapore, norm=norm\n",
    "    )\n",
    "    visualise_singapore_outline(ax=axi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rainfall_rates = (\n",
    "    weather_station_df_pivot.iloc[1773:1797].resample(\"15min\").first()[\"rain_rate\"]\n",
    ")\n",
    "\n",
    "\n",
    "print(original_rainfall_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_arr = []\n",
    "pred_arr = []\n",
    "\n",
    "for idx, timestamp in enumerate(out):\n",
    "    output = {}\n",
    "    count = 0\n",
    "    a_arr = []\n",
    "    p_arr = []\n",
    "\n",
    "    for stn in general_station:\n",
    "        output[stn] = float(timestamp[count])\n",
    "        count += 1\n",
    "    for stn in rainfall_station:\n",
    "        output[stn] = float(timestamp[count])\n",
    "        count += 1\n",
    "\n",
    "    for key, value in output.items():\n",
    "        a_arr.append(original_rainfall_rates.iloc[idx][key])\n",
    "        p_arr.append(output[key])\n",
    "    a_arr = list(map(lambda x: float(x), a_arr))\n",
    "    actual_arr.append(a_arr)\n",
    "    pred_arr.append(p_arr)\n",
    "\n",
    "actual_arr = np.array(actual_arr)\n",
    "pred_arr = np.array(pred_arr)\n",
    "\n",
    "print(actual_arr)\n",
    "print(pred_arr)\n",
    "error = []\n",
    "for i in range(len(actual_arr)):\n",
    "    error.append(np.nanmean(actual_arr - pred_arr) ** 2)\n",
    "\n",
    "MSE = np.mean(np.array(error))\n",
    "print(MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_rainfall_rates.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainfall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
