{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from benchmarks.models.idw import run_IDW_benchmark\n",
    "from benchmarks.models.kriging import kriging_external_drift\n",
    "\n",
    "from utils.load import *\n",
    "from utils.visualisation import *\n",
    "from utils.sampling import stratified_spatial_sampling_dual\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab223e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f61a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_df = load_radar_dataset(folder_name='sg_radar_data')\n",
    "raingauge_df = load_raingauge_dataset('rainfall_data.csv', N=0)\n",
    "cml_df = load_cml_dataset('CML_data_processed_2025.nc')\n",
    "print(radar_df.shape)\n",
    "print(raingauge_df.shape)\n",
    "print(cml_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767a124",
   "metadata": {},
   "source": [
    "# Load station split and process rain gauge stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_dict = get_station_coordinate_mappings()\n",
    "station_split = stratified_spatial_sampling_dual(station_dict, seed=123, plot=False)\n",
    "\n",
    "training_stations=station_split['statistical']['train']\n",
    "test_stations=station_split['statistical']['test']\n",
    "\n",
    "#Rain gauge choices: Resample either to 5 or 15 minute intervals\n",
    "raingauge_df_5mins = raingauge_df.mul(12)\n",
    "raingauge_df_15mins = raingauge_df.resample('15min').mean().mul(12) #resamples to 15 mins and converts to mm/hour rainfall rate\n",
    "\n",
    "raingauge_choice_df = raingauge_df_15mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b3ad6",
   "metadata": {},
   "source": [
    "# IDW Interpolation with rain gauge\n",
    "Interpolation was conducted with both rain gauge sampling done at 5 minute and 15 minute intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridx = np.arange(103.605, 104.1, 0.01)\n",
    "gridy = np.arange(1.145, 1.51, 0.01)\n",
    "gridy = gridy[::-1] #invert the y-axis to correspond with correct orientation of map output\n",
    "\n",
    "fig, ax = plt.subplots(3,3, sharex=True, sharey=True, figsize=(10,10))\n",
    "\n",
    "#With plotting\n",
    "idw_RMSE = run_IDW_benchmark(raingauge_choice_df,\n",
    "                             coordinates=station_dict,\n",
    "                             training_stations=training_stations,\n",
    "                             test_stations=test_stations,\n",
    "                             power=2, \n",
    "                             loss_hist=False,\n",
    "                             x_grid=gridx, \n",
    "                             y_grid=gridy, \n",
    "                             ax=ax,\n",
    "                             axis_cols=3,\n",
    "                             axis_rows=3,\n",
    "                             plot_time_start=pd.Timestamp(\"2025-02-05 04:15:00\"),\n",
    "                             n_nearest=15,\n",
    "                             regression_plot=True\n",
    "                             )\n",
    "\n",
    "\n",
    "# #Without plotting\n",
    "# idw_RMSE = run_IDW_benchmark(raingauge_choice_df,\n",
    "#                              coordinates=station_dict,\n",
    "#                              training_stations=training_stations,\n",
    "#                              validation_stations=validation_stations,\n",
    "#                              power=2, \n",
    "#                              loss_hist=False,\n",
    "#                              x_grid=gridx, \n",
    "#                              y_grid=gridy,\n",
    "#                              n_nearest=5\n",
    "#                              )\n",
    "for idx, axi in enumerate(ax.flatten()):\n",
    "  visualise_singapore_outline(ax = axi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to merge radar data with rain gauge data for KED\n",
    "\n",
    "merged_df_KED = pd.merge(raingauge_choice_df, radar_df, on='time_sgt')\n",
    "merged_df = raingauge_choice_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf2653",
   "metadata": {},
   "source": [
    "# Kriging interpolation with rain gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "invalid_kriges = 0\n",
    "training_ratio = config['dataset_parameters']['train_size']\n",
    "station_names = []\n",
    "\n",
    "for key in station_dict.keys():\n",
    "  station_names.append(key,)\n",
    "\n",
    "actual_values_arr = np.zeros(shape=[merged_df.shape[0], len(test_stations)])\n",
    "predicted_values_arr = np.zeros(shape=[merged_df.shape[0], len(test_stations)])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for idx in tqdm(range(len(merged_df_KED))):\n",
    "  df = merged_df_KED.iloc[idx]\n",
    "\n",
    "  kriging_result, kriging_variance = kriging_external_drift(df=df, \n",
    "                                                            station_names=training_stations, \n",
    "                                                            station_dict=station_dict, \n",
    "                                                            variogram_model='exponential', \n",
    "                                                            method='ordinary')\n",
    "\n",
    "  if kriging_result is None:\n",
    "    invalid_kriges += 1\n",
    "    continue\n",
    "\n",
    "    \n",
    "  row_predicted_arr = []\n",
    "  row_actual_arr = []\n",
    "  \n",
    "  #Calculate loss\n",
    "  for test_station in test_stations:\n",
    "    if not np.isnan(df[test_station]):\n",
    "      rain_gauge_value = df[test_station]\n",
    "      lat, lon = station_dict[test_station]\n",
    "      row = math.floor((1.51 - lat) / 0.01)\n",
    "      col = math.floor((lon - 103.6) / 0.01)\n",
    "      kriged_value = kriging_result[row][col]\n",
    "\n",
    "      row_actual_arr.append(rain_gauge_value)\n",
    "      row_predicted_arr.append(max(0, kriged_value)) ## Kriged values can be negative and thus we need to account for this and set neg values to 0\n",
    "    else:\n",
    "      row_actual_arr.append(np.nan)\n",
    "      row_predicted_arr.append(np.nan)\n",
    "    \n",
    "  actual_values_arr[idx] = np.array(row_actual_arr)\n",
    "  predicted_values_arr[idx] = np.array(row_predicted_arr)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "MSE_arr = []\n",
    "\n",
    "assert(len(actual_values_arr) == len(predicted_values_arr))\n",
    "\n",
    "#calculate loss\n",
    "for i in range(len(actual_values_arr)):\n",
    "  pred = predicted_values_arr[i]\n",
    "  act = actual_values_arr[i]\n",
    "  mask = ~np.isnan(act)\n",
    "  MSE = np.mean((pred[mask] - act[mask]) ** 2)\n",
    "  MSE_arr.append(MSE)\n",
    "\n",
    "average_RMSE_loss = np.sum(np.sqrt(np.array(MSE_arr))) / len(merged_df)\n",
    "average_MSE_loss = np.sum(np.array(MSE_arr)) / len(merged_df)\n",
    "\n",
    "print(f\"invalid kriges: {invalid_kriges}\")\n",
    "print(f\"final average loss: {average_RMSE_loss}\")\n",
    "#print(f\"final average loss (0 rain = 0 loss): {total_RMSE_loss / (len(raingauge_choice_df))}\")\n",
    "print(f\"Time taken = {end - start}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "actual = np.array(actual_values_arr).flatten()\n",
    "predicted = np.array(predicted_values_arr).flatten()\n",
    "mask = ~np.isnan(actual)\n",
    "\n",
    "# plt.hist2d(x=actual[mask], y=predicted[mask],\n",
    "#                   bins=100, \n",
    "#                   cmap='jet',\n",
    "#                   cmin=1,\n",
    "#                   norm=LogNorm(vmin=1, vmax=None))\n",
    "plt.scatter(x=actual, y=predicted)\n",
    "\n",
    "plot_bound = max(np.nanmax(actual).astype(int),np.nanmax(predicted).astype(int))\n",
    "plt.plot(np.linspace(0,plot_bound,100),\n",
    "        np.linspace(0,plot_bound,100))\n",
    "plt.xlabel('actual_values')\n",
    "plt.ylabel('predicted_values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pearson_correlation, _ = pearsonr(actual[mask], predicted[mask])\n",
    "print(f\"Pearson correlation: {pearson_correlation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
