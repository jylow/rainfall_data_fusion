{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.sampling import stratified_spatial_sampling_dual\n",
    "from utils.load import *\n",
    "from data.weather_graph_dataset import WeatherGraphDataset\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_data = load_weather_station_dataset('weather_station_data.csv')\n",
    "weather_station_locations = get_station_coordinate_mappings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b30b43",
   "metadata": {},
   "source": [
    "# Preprocess station data.\n",
    "Some stations only contain rainfall information but some stations contain both rainfall and other information.\n",
    "We will split these stations into weather station and general stations \n",
    "\n",
    "Additional info: \n",
    "  Windspeed\n",
    "  Wind Direction\n",
    "  Temperature\n",
    "  Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99070e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(weather_station_data.columns)\n",
    "cols.remove('time_sgt')\n",
    "cols.remove('gid')\n",
    "weather_station_df_pivot = pd.pivot(data=weather_station_data, index='time_sgt', columns='gid', values=cols)\n",
    "weather_station_df_counts = weather_station_df_pivot.count().reset_index()\n",
    "\n",
    "weather_station_info = pd.pivot(data=weather_station_df_counts, index='gid', columns = 'level_0')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "rainfall_station = [row[0] for row in weather_station_info.iterrows() if 0 in row[1].value_counts()]\n",
    "general_station = [s for s in weather_station_locations if s not in rainfall_station]\n",
    "\n",
    "print(rainfall_station)\n",
    "print(general_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "general_station_data = {}\n",
    "rainfall_station_data = {}\n",
    "for station in weather_station_df_pivot.columns.get_level_values(1).unique():\n",
    "    station_cols = weather_station_df_pivot.xs(station, level=1, axis=1).interpolate(method='linear').fillna(method='ffill').fillna(method='bfill')\n",
    "    if station in general_station:\n",
    "      general_station_data[station] = station_cols.values \n",
    "    else:\n",
    "      rainfall_station_data[station] = station_cols.values[:, 0:1]\n",
    "\n",
    "print(rainfall_station_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26124db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "general_station_features = []\n",
    "rainfall_station_features = []\n",
    "for station in general_station:\n",
    "  station_feat = general_station_data[station]\n",
    "  general_station_features.append(station_feat)\n",
    "\n",
    "for station in rainfall_station:\n",
    "  station_feat = rainfall_station_data[station]\n",
    "  rainfall_station_features.append(station_feat)\n",
    "\n",
    "dtype = torch.float32\n",
    "data['general_station'].x = torch.tensor(np.array(general_station_features).transpose(1, 0, 2), dtype=dtype)\n",
    "data['rainfall_station'].x = torch.tensor(np.array(rainfall_station_features).transpose(1,0,2), dtype=dtype)\n",
    "\n",
    "data['general_station'].y = torch.tensor(np.array(general_station_features)[:,:,0:1].transpose(1,0,2), dtype=dtype)\n",
    "data['rainfall_station'].y = torch.tensor(np.array(rainfall_station_features).transpose(1,0,2), dtype=dtype)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853908c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_info = stratified_spatial_sampling_dual(weather_station_locations)\n",
    "print(split_info)\n",
    "\n",
    "data['general_station'].train_mask = [1 if station in split_info['ml']['train'] else 0 for station in general_station]\n",
    "data['general_station'].val_mask = [1 if station in split_info['ml']['validation'] else 0 for station in general_station]\n",
    "data['general_station'].test_mask = [1 ^ (x | y) for x,y in zip(data['general_station'].train_mask, data['general_station'].val_mask)]\n",
    "\n",
    "data['rainfall_station'].train_mask = [1 if station in split_info['ml']['train'] else 0 for station in rainfall_station]\n",
    "data['rainfall_station'].val_mask = [1 if station in split_info['ml']['validation'] else 0 for station in rainfall_station]\n",
    "data['rainfall_station'].test_mask = [1 ^ (x | y) for x,y in zip(data['rainfall_station'].train_mask, data['rainfall_station'].val_mask)]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae33c3",
   "metadata": {},
   "source": [
    "# Edge generation\n",
    "We consider the location of the stations when performing our edge generation. \n",
    "General station locations and rainfall station locations will be considered the same and we will make a connection across the nodes if required. This will ensure that we can connect both the layers together in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable to determine number of neighbours per node\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "K = 4 \n",
    "\n",
    "print(weather_station_locations)\n",
    "ids = list(weather_station_locations.keys())\n",
    "print(ids)\n",
    "coords = np.array(list(weather_station_locations.values()))\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=K+1, algorithm='ball_tree')\n",
    "knn.fit(coords)\n",
    "\n",
    "distances, indices = knn.kneighbors(coords)\n",
    "\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "edges = {\n",
    "        'rainfall_to_rainfall': [],  \n",
    "        'rainfall_to_general': [],    \n",
    "        'general_to_rainfall': [],  \n",
    "        'general_to_general': []      \n",
    "    }\n",
    "\n",
    "for idx, row in enumerate(indices):\n",
    "  origin = row[0]\n",
    "  for n in row[1:]: \n",
    "    if ids[origin] in rainfall_station:\n",
    "      start_id = rainfall_station.index(ids[origin])\n",
    "      if ids[n] in rainfall_station:\n",
    "        end_id = rainfall_station.index(ids[n])\n",
    "        edges['rainfall_to_rainfall'].append([start_id, end_id])\n",
    "      else:\n",
    "        end_id = general_station.index(ids[n])\n",
    "        edges['rainfall_to_general'].append([start_id, end_id])\n",
    "    else:\n",
    "      start_id = general_station.index(ids[origin])\n",
    "      if ids[n] in rainfall_station:\n",
    "        end_id = rainfall_station.index(ids[n])\n",
    "        edges['general_to_rainfall'].append([start_id, end_id])\n",
    "      else:\n",
    "        end_id = general_station.index(ids[n])\n",
    "        edges['general_to_general'].append([start_id, end_id])\n",
    "\n",
    "G.add_edges_from(edges['rainfall_to_rainfall'])\n",
    "\n",
    "for key, val in edges.items():\n",
    "  xarr = []\n",
    "  yarr = []\n",
    "  for x, y in val:\n",
    "    xarr.append(x)\n",
    "    yarr.append(y)\n",
    "  edges[key] = [xarr, yarr]\n",
    "\n",
    "\n",
    "data['general_station', 'gen_to_rain', 'rainfall_station'].edge_index = torch.tensor(edges['general_to_rainfall'], dtype=torch.int64)\n",
    "data['rainfall_station', 'rain_to_gen', 'general_station'].edge_index = torch.tensor(edges['rainfall_to_general'], dtype=torch.int64)\n",
    "data['general_station', 'gen_to_gen', 'general_station'].edge_index = torch.tensor(edges['general_to_general'], dtype=torch.int64)\n",
    "data['rainfall_station', 'rain_to_rain', 'rainfall_station'].edge_index = torch.tensor(edges['rainfall_to_rainfall'], dtype=torch.int64)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f959a81",
   "metadata": {},
   "source": [
    "# Creating the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131359f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, HeteroConv, GCNConv, GATConv, Linear\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('general_station', 'gen_to_gen', 'general_station'): GCNConv(-1, hidden_channels),\n",
    "                ('general_station', 'gen_to_rain', 'rainfall_station'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('rainfall_station', 'rain_to_gen', 'general_station'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('rainfall_station', 'rain_to_rain', 'rainfall_station'): GCNConv(-1, hidden_channels),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin_rainfall = Linear(hidden_channels, out_channels)\n",
    "        self.lin_general = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "\n",
    "        gen_out = self.lin_general(x_dict['general_station'])\n",
    "        rain_out = self.lin_rainfall(x_dict['rainfall_station'])\n",
    "\n",
    "        return{\n",
    "            'general_station': gen_out,\n",
    "            'rainfall_station': rain_out\n",
    "        }\n",
    "\n",
    "model = HeteroGNN(hidden_channels=4, out_channels=1,\n",
    "                  num_layers=2)\n",
    "\n",
    "model.to(device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "def collate_temporal_graphs(batch):\n",
    "  gen_x = torch.stack([item['gen_x'] for item in batch])\n",
    "  rain_x = torch.stack([item['rain_x'] for item in batch])\n",
    "  gen_y = torch.stack([item['gen_y'] for item in batch])\n",
    "  rain_y = torch.stack([item['rain_y'] for item in batch])\n",
    "  \n",
    "  return {\n",
    "      'gen_x': gen_x,\n",
    "      'rain_x': rain_x,\n",
    "      'gen_y': gen_y,\n",
    "      'rain_y': rain_y\n",
    "  }\n",
    "\n",
    "def train_epoch(model, data, dataloader, optimizer, device):\n",
    "  model.train()\n",
    "  total_training_loss = 0\n",
    "\n",
    "  train_gen_mask = torch.tensor(data['general_station'].train_mask, dtype=torch.bool).to(device)\n",
    "  train_rain_mask = torch.tensor(data['rainfall_station'].train_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  edge_index_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "  }\n",
    "  for batch in tqdm.tqdm(dataloader, desc=\"training\"):\n",
    "    gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "    rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "    gen_y = batch['gen_y'].to(device)\n",
    "    rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "    batch_size = gen_x.shape[0]\n",
    "\n",
    "    batch_loss = 0\n",
    "    for i in range(batch_size):\n",
    "\n",
    "      x_dict = {\n",
    "        'general_station': gen_x[i],\n",
    "        'rainfall_station': rain_x[i]\n",
    "      }\n",
    "      optimizer.zero_grad()\n",
    "      out = model(x_dict, edge_index_dict)\n",
    "\n",
    "\n",
    "      gen_predictions = out['general_station'][train_gen_mask]\n",
    "      rain_predictions = out['rainfall_station'][train_rain_mask]\n",
    "\n",
    "\n",
    "      training_loss = F.mse_loss(gen_predictions, gen_y[i][train_gen_mask]) + F.mse_loss(rain_predictions, rain_y[i][train_rain_mask])\n",
    "      batch_loss += training_loss\n",
    "\n",
    "    batch_loss = batch_loss / batch_size \n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    total_training_loss += batch_loss.item()\n",
    " \n",
    "  return total_training_loss/len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data, dataloader, device):\n",
    "  total_validation_loss = 0\n",
    "\n",
    "  val_gen_mask = torch.tensor(data['general_station'].val_mask, dtype=torch.bool).to(device)\n",
    "  val_rain_mask = torch.tensor(data['rainfall_station'].val_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  edge_index_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "  }\n",
    "  for batch in tqdm.tqdm(dataloader, desc=\"validation\"):\n",
    "    gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "    rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "    gen_y = batch['gen_y'].to(device)\n",
    "    rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "    batch_size = gen_x.shape[0]\n",
    "\n",
    "    batch_loss = 0\n",
    "    for i in range(batch_size):\n",
    "\n",
    "      x_dict = {\n",
    "        'general_station': gen_x[i],\n",
    "        'rainfall_station': rain_x[i]\n",
    "      }\n",
    "      out = model(x_dict, edge_index_dict)\n",
    "\n",
    "\n",
    "      gen_predictions = out['general_station'][val_gen_mask]\n",
    "      rain_predictions = out['rainfall_station'][val_rain_mask]\n",
    "\n",
    "\n",
    "      validation_loss = F.mse_loss(gen_predictions, gen_y[i][val_gen_mask]) + F.mse_loss(rain_predictions, rain_y[i][val_rain_mask])\n",
    "      \n",
    "  \n",
    "      batch_loss += validation_loss.item()\n",
    "    total_validation_loss += batch_loss\n",
    " \n",
    "  return total_validation_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c428c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "batch_size=16\n",
    "train_dataset = WeatherGraphDataset(data, mode='train')\n",
    "val_dataset = WeatherGraphDataset(data, mode='val')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False,\n",
    "  collate_fn=collate_temporal_graphs\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "  val_dataset,\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False,\n",
    "  collate_fn=collate_temporal_graphs\n",
    ")\n",
    "\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "training_loss_arr = []\n",
    "validation_loss_arr = []\n",
    "\n",
    "for i in range(10):\n",
    "  train_loss = train_epoch(model, data, train_loader, optimizer, device)\n",
    "  validation_loss = validate(model, data, test_loader, device)\n",
    "  training_loss_arr.append(train_loss)\n",
    "  validation_loss_arr.append(validation_loss)\n",
    "\n",
    "  print(f\"Train Loss: {train_loss:.4f}\")\n",
    "  print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "\n",
    "plt.plot(training_loss_arr, label='training_loss', color='blue')\n",
    "plt.plot(validation_loss_arr, label='validation_loss', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fdc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35259636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def test_model():\n",
    "  model.eval()\n",
    "  total_rmse = 0\n",
    "\n",
    "  plot_preds = np.array([])\n",
    "  plot_actual = np.array([])\n",
    "\n",
    "  test_dataset = WeatherGraphDataset(data, mode='test')\n",
    "\n",
    "  gen_mask = torch.tensor(data['general_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  rain_mask = torch.tensor(data['rainfall_station'].test_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  edge_index_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "  }\n",
    "\n",
    "  dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_temporal_graphs\n",
    "  )\n",
    "\n",
    "  count = 0\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(dataloader, desc=\"testing\"):\n",
    "      gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "      rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "      gen_y = batch['gen_y'].to(device)\n",
    "      rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "      batch_size = gen_x.shape[0]\n",
    "\n",
    "      batch_rmse = 0\n",
    "      for i in range(batch_size):\n",
    "\n",
    "        x_dict = {\n",
    "          'general_station': gen_x[i],\n",
    "          'rainfall_station': rain_x[i]\n",
    "        }\n",
    "\n",
    "        out = model(x_dict, edge_index_dict)\n",
    "\n",
    "        gen_predictions = out['general_station'][gen_mask]\n",
    "        rain_predictions = out['rainfall_station'][rain_mask]\n",
    "\n",
    "        # print(\"GEN preds\")\n",
    "        # print(gen_predictions)\n",
    "        # print(\"rain preds\")\n",
    "        # print(rain_predictions)\n",
    "\n",
    "        gen_targets = gen_y[i][gen_mask]\n",
    "        rain_targets = rain_y[i][rain_mask]\n",
    "        # print(gen_targets.detach().numpy().flatten())\n",
    "\n",
    "        plot_preds = np.concatenate((plot_preds, gen_predictions.detach().numpy().flatten(), rain_predictions.detach().numpy().flatten()))\n",
    "        plot_actual = np.concatenate((plot_actual, gen_targets.detach().numpy().flatten(), rain_targets.detach().numpy().flatten()))\n",
    "\n",
    "        # print(\"Gen targets\")\n",
    "        # print(gen_targets)\n",
    "        # print(\"Rain targets\")\n",
    "        # print(rain_targets)\n",
    "\n",
    "        gen_MSE_arr = (gen_predictions - gen_targets) ** 2\n",
    "        rain_MSE_arr = (rain_predictions - rain_targets) ** 2\n",
    "\n",
    "        # print(\"GEN\")\n",
    "        # print(gen_MSE_arr)\n",
    "        # print(\"Rain\")\n",
    "        # print(rain_MSE_arr)\n",
    "\n",
    "        all_squared_errors = torch.cat([gen_MSE_arr, rain_MSE_arr])\n",
    "        test_rmse = torch.sqrt(torch.mean(all_squared_errors))\n",
    "\n",
    "        batch_rmse += test_rmse.item()\n",
    "        count += 1\n",
    "\n",
    "      total_rmse += batch_rmse\n",
    " \n",
    "  plt.scatter(x=plot_actual, y=plot_preds)\n",
    "  plot_bound = max(np.nanmax(plot_actual).astype(int),np.nanmax(plot_preds).astype(int))\n",
    "  plt.plot(np.linspace(0,plot_bound,100),\n",
    "            np.linspace(0,plot_bound,100))\n",
    "  plt.xlabel(\"actual rainfall\")\n",
    "  plt.ylabel(\"predicted rainfall\")\n",
    "\n",
    "  mask = ~np.isnan(plot_actual)\n",
    "  pearson_r_global, pearson_p_global = pearsonr(plot_actual[mask], plot_preds[mask])\n",
    "\n",
    "  print(f\"Pearson correlation: {pearson_r_global}\")\n",
    "  return total_rmse/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff01a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = test_model()\n",
    "print(f\"TEST RMSE: {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606be2d",
   "metadata": {},
   "source": [
    "# Visualisation of output\n",
    "Test event will be 02-05-2025 0415 to 0615\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c852b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_event_data = weather_station_df_pivot.iloc[1772:1798].resample('15min').first()\n",
    "test_data = data.clone()\n",
    "\n",
    "test_general_station_data = {}\n",
    "test_rainfall_station_data = {}\n",
    "\n",
    "for station in test_event_data.columns.get_level_values(1).unique():\n",
    "    station_cols = test_event_data.xs(station, level=1, axis=1).interpolate(method='linear').fillna(method='ffill').fillna(method='bfill')\n",
    "    if station in general_station:\n",
    "      test_general_station_data[station] = station_cols.values \n",
    "    else:\n",
    "      test_rainfall_station_data[station] = station_cols.values[:, 0:1]\n",
    "# print(test_general_station_data)\n",
    "# print(test_rainfall_station_data)\n",
    "\n",
    "test_general_station_features = []\n",
    "test_rainfall_station_features = []\n",
    "\n",
    "for station in general_station:\n",
    "  if station in test_general_station_data:\n",
    "    station_feat = test_general_station_data[station]\n",
    "    test_general_station_features.append(station_feat)\n",
    "\n",
    "for station in rainfall_station:\n",
    "  if station in test_rainfall_station_data:\n",
    "    station_feat = test_rainfall_station_data[station]\n",
    "    test_rainfall_station_features.append(station_feat)\n",
    "\n",
    "# print(test_general_station_features)\n",
    "# print(test_rainfall_station_features)\n",
    "\n",
    "test_data['general_station'].x = torch.tensor(np.array(test_general_station_features).transpose(1,0,2), dtype=torch.float)\n",
    "test_data['general_station'].y = torch.tensor(np.array(test_general_station_features)[:, :,0:1].transpose(1,0,2), dtype=torch.float)\n",
    "test_data['rainfall_station'].x = torch.tensor(np.array(test_rainfall_station_features).transpose(1,0,2), dtype=torch.float) \n",
    "test_data['rainfall_station'].y = torch.tensor(np.array(test_rainfall_station_features).transpose(1,0,2), dtype=torch.float)  \n",
    "\n",
    "out = model(test_data.x_dict, test_data.edge_index_dict)\n",
    "print(out)\n",
    "gen_out = out['general_station'].detach().numpy()\n",
    "rain_out = out['rainfall_station'].detach().numpy()\n",
    "\n",
    "print(gen_out.shape)\n",
    "print(rain_out.shape)\n",
    "out_np = np.concatenate([gen_out, rain_out], axis=1)\n",
    "print(out_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca57f6f",
   "metadata": {},
   "source": [
    "# Visualise rain on radar grid\n",
    "Hard coded to plot only consequitive 9 timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import *\n",
    "from utils.visualisation import *\n",
    "radar_df = load_radar_dataset('radar_vis')\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize=(15,12), subplot_kw={'projection' : ccrs.PlateCarree()})\n",
    "\n",
    "bounds_singapore = {\n",
    "  'left': 103.6,\n",
    "  'right': 104.1,\n",
    "  'top': 1.5,\n",
    "  'bottom': 1.188\n",
    "}\n",
    "bounds = [0.1, 0.2, 0.5, 1, 2, 4, 7, 10, 20] \n",
    "norm = mpl.colors.BoundaryNorm(boundaries=bounds, ncolors=256, extend='both')\n",
    "\n",
    "for idx, timestamp in enumerate(out_np):\n",
    "  output = {}\n",
    "  count = 0\n",
    "  \n",
    "  for stn in general_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  for stn in rainfall_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  axi = ax[idx // 3][idx % 3]\n",
    "  node_df = pd.Series(output)\n",
    "  node_df = pandas_to_geodataframe(node_df)\n",
    "  print(node_df)\n",
    "  # visualise_gauge_grid(node_df=node_df, ax=axi)\n",
    "  # improved_visualise_radar_grid(radar_df.iloc[idx], ax=axi, zoom=bounds_singapore)\n",
    "  # visualise_singapore_outline(ax=axi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rainfall_rates = weather_station_df_pivot.iloc[1773:1797].resample('15min').first()['rain_rate']\n",
    "\n",
    "\n",
    "print(original_rainfall_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_arr = []\n",
    "pred_arr = []\n",
    "\n",
    "for idx, timestamp in enumerate(out):\n",
    "  output = {}\n",
    "  count = 0\n",
    "  a_arr = []\n",
    "  p_arr = []\n",
    "  \n",
    "  for stn in general_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  for stn in rainfall_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "\n",
    "  for key, value in output.items():\n",
    "    a_arr.append(original_rainfall_rates.iloc[idx][key])\n",
    "    p_arr.append(output[key])\n",
    "  a_arr = list(map(lambda x: float(x), a_arr))\n",
    "  actual_arr.append(a_arr)\n",
    "  pred_arr.append(p_arr)\n",
    "\n",
    "actual_arr = np.array(actual_arr)\n",
    "pred_arr = np.array(pred_arr)\n",
    "\n",
    "print(actual_arr)\n",
    "print(pred_arr)\n",
    "error = []\n",
    "for i in range(len(actual_arr)):\n",
    "  error.append(np.nanmean(actual_arr - pred_arr) ** 2)\n",
    "\n",
    "MSE = np.mean(np.array(error))\n",
    "print(MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_rainfall_rates.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
