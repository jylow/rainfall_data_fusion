{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.sampling import stratified_spatial_sampling_dual\n",
    "from src.utils import *\n",
    "from data.weather_graph_dataset import WeatherGraphDataset\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from src.graphbuilder import GraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_data = load_weather_station_dataset('weather_station_data.csv')\n",
    "weather_station_locations = get_station_coordinate_mappings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(weather_station_locations.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a431912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(weather_station_data['gid'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b30b43",
   "metadata": {},
   "source": [
    "# Preprocess station data.\n",
    "Some stations only contain rainfall information but some stations contain both rainfall and other information.\n",
    "We will split these stations into weather station and general stations \n",
    "\n",
    "Additional info: \n",
    "  Windspeed\n",
    "  Wind Direction\n",
    "  Temperature\n",
    "  Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99070e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(weather_station_data.columns)\n",
    "cols.remove('time_sgt')\n",
    "cols.remove('gid')\n",
    "\n",
    "weather_station_df_pivot = pd.pivot(data=weather_station_data, index='time_sgt', columns='gid', values=cols).resample('15min').first()\n",
    "weather_station_df_pivot['rain_rate'] = weather_station_df_pivot['rain_rate'] * 12\n",
    "weather_station_df_counts = weather_station_df_pivot.count().reset_index()\n",
    "\n",
    "weather_station_info = pd.pivot(data=weather_station_df_counts, index='gid', columns = 'level_0')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "rainfall_station = [row[0] for row in weather_station_info.iterrows() if 0 in row[1].value_counts()]\n",
    "general_station = [s for s in weather_station_locations if s not in rainfall_station]\n",
    "\n",
    "print(rainfall_station)\n",
    "print(general_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in weather_station_df_pivot['rain_rate'].iterrows():\n",
    "  if np.nansum(row[1].to_numpy()) != 0:\n",
    "    count += 1\n",
    "print(f\"Number of timesteps that contain rain: {count}\")\n",
    "print(f\"Total_timesteps = {weather_station_df_pivot.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "general_station_data = {}\n",
    "rainfall_station_data = {}\n",
    "for station in weather_station_df_pivot.columns.get_level_values(1).unique():\n",
    "    station_cols = weather_station_df_pivot.xs(station, level=1, axis=1).interpolate(method='linear').fillna(method='ffill').fillna(method='bfill')\n",
    "    if station in general_station:\n",
    "      general_station_data[station] = station_cols.values\n",
    "    else:\n",
    "      rainfall_station_data[station] = station_cols.values[:, 0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04741f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_station_temp = [stn for stn in general_station if stn != \"S108\"]\n",
    "general_station = general_station_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26124db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "general_station_features = []\n",
    "rainfall_station_features = []\n",
    "for station in general_station:\n",
    "  station_feat = general_station_data[station]\n",
    "  general_station_features.append(station_feat)\n",
    "\n",
    "for station in rainfall_station:\n",
    "  station_feat = rainfall_station_data[station]\n",
    "  rainfall_station_features.append(station_feat)\n",
    "\n",
    "dtype = torch.float32\n",
    "data['general_station'].x = torch.tensor(np.array(general_station_features).transpose(1, 0, 2), dtype=dtype)\n",
    "data['rainfall_station'].x = torch.tensor(np.array(rainfall_station_features).transpose(1,0,2), dtype=dtype)\n",
    "\n",
    "data['general_station'].y = torch.tensor(np.array(general_station_features)[:,:,0:1].transpose(1,0,2), dtype=dtype)\n",
    "data['rainfall_station'].y = torch.tensor(np.array(rainfall_station_features).transpose(1,0,2), dtype=dtype)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853908c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_info = stratified_spatial_sampling_dual(weather_station_locations, seed=1111)\n",
    "print(split_info)\n",
    "\n",
    "data['general_station'].train_mask = [1 if station in split_info['ml']['train'] else 0 for station in general_station]\n",
    "data['general_station'].val_mask = [1 if station in split_info['ml']['validation'] else 0 for station in general_station]\n",
    "data['general_station'].test_mask = [1 if (x == 0 and y == 0) else 0 for x,y in zip(data['general_station'].train_mask, data['general_station'].val_mask)]\n",
    "\n",
    "data['rainfall_station'].train_mask = [1 if station in split_info['ml']['train'] else 0 for station in rainfall_station]\n",
    "data['rainfall_station'].val_mask = [1 if station in split_info['ml']['validation'] else 0 for station in rainfall_station]\n",
    "data['rainfall_station'].test_mask = [1 if (x == 0 and y == 0) else 0 for x,y in zip(data['rainfall_station'].train_mask, data['rainfall_station'].val_mask)]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae33c3",
   "metadata": {},
   "source": [
    "# Edge generation\n",
    "We consider the location of the stations when performing our edge generation. \n",
    "General station locations and rainfall station locations will be considered the same and we will make a connection across the nodes if required. This will ensure that we can connect both the layers together in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_distance(a, b):\n",
    "  return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable to determine number of neighbours per node\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "K = 4\n",
    "\n",
    "ids = general_station + rainfall_station\n",
    "print(ids)\n",
    "\n",
    "coordinates = []\n",
    "for id in ids:\n",
    "  coordinates.append(weather_station_locations[id])\n",
    "coords = np.array(coordinates)\n",
    "\n",
    "print(coords)\n",
    "knn = NearestNeighbors(n_neighbors=K+1, algorithm='ball_tree')\n",
    "knn.fit(coords)\n",
    "\n",
    "distances, indices = knn.kneighbors(coords)\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "edges = {\n",
    "        'rainfall_to_rainfall': [],  \n",
    "        'rainfall_to_general': [],    \n",
    "        'general_to_rainfall': [],  \n",
    "        'general_to_general': []      \n",
    "    }\n",
    "\n",
    "edge_attributes = {\n",
    "        'rainfall_to_rainfall': [],  \n",
    "        'rainfall_to_general': [],    \n",
    "        'general_to_rainfall': [],  \n",
    "        'general_to_general': []      \n",
    "}\n",
    "\n",
    "#add station coordinates for nx plotting\n",
    "for idx, station in enumerate(general_station + rainfall_station):\n",
    "  G.add_node(idx, pos=(weather_station_locations[station][1], weather_station_locations[station][0]))\n",
    "color_map = ['green' for i in range(len(general_station))] + ['red' for i in range(len(rainfall_station))]\n",
    "\n",
    "for idx, row in enumerate(indices):\n",
    "  origin = row[0]\n",
    "  \n",
    "  for n in row[1:]: \n",
    "    G.add_edge(origin, n)\n",
    "    if ids[origin] in rainfall_station:\n",
    "      start_id = rainfall_station.index(ids[origin])\n",
    "      if ids[n] in rainfall_station:\n",
    "        end_id = rainfall_station.index(ids[n])\n",
    "        edges['rainfall_to_rainfall'].append([start_id, end_id])\n",
    "        edge_attributes['rainfall_to_rainfall'].append([get_distance(weather_station_locations[ids[origin]], weather_station_locations[ids[n]])])\n",
    "      else:\n",
    "        end_id = general_station.index(ids[n])\n",
    "        edges['rainfall_to_general'].append([start_id, end_id])\n",
    "        edge_attributes['rainfall_to_general'].append([get_distance(weather_station_locations[ids[origin]], weather_station_locations[ids[n]])])\n",
    "    else:\n",
    "      start_id = general_station.index(ids[origin])\n",
    "      if ids[n] in rainfall_station:\n",
    "        end_id = rainfall_station.index(ids[n])\n",
    "        edges['general_to_rainfall'].append([start_id, end_id])\n",
    "        edge_attributes['general_to_rainfall'].append([get_distance(weather_station_locations[ids[origin]], weather_station_locations[ids[n]])])\n",
    "      else:\n",
    "        end_id = general_station.index(ids[n])\n",
    "        edges['general_to_general'].append([start_id, end_id])\n",
    "        edge_attributes['general_to_general'].append([get_distance(weather_station_locations[ids[origin]], weather_station_locations[ids[n]])])\n",
    "\n",
    "print(G)\n",
    "print(len(list(nx.connected_components(G))))\n",
    "nx.draw(G, nx.get_node_attributes(G, 'pos'), node_color = color_map, with_labels=True, font_weight='bold')\n",
    "\n",
    "for key, val in edges.items():\n",
    "  xarr = []\n",
    "  yarr = []\n",
    "  for x, y in val:\n",
    "    xarr.append(x)\n",
    "    yarr.append(y)\n",
    "  edges[key] = [xarr, yarr]\n",
    "\n",
    "\n",
    "data['general_station', 'gen_to_rain', 'rainfall_station'].edge_index = torch.tensor(edges['general_to_rainfall'], dtype=torch.int64)\n",
    "data['rainfall_station', 'rain_to_gen', 'general_station'].edge_index = torch.tensor(edges['rainfall_to_general'], dtype=torch.int64)\n",
    "data['general_station', 'gen_to_gen', 'general_station'].edge_index = torch.tensor(edges['general_to_general'], dtype=torch.int64)\n",
    "data['rainfall_station', 'rain_to_rain', 'rainfall_station'].edge_index = torch.tensor(edges['rainfall_to_rainfall'], dtype=torch.int64)\n",
    "\n",
    "data['general_station', 'gen_to_rain', 'rainfall_station'].edge_attr = torch.tensor(edge_attributes['general_to_rainfall'], dtype=torch.float32)\n",
    "data['rainfall_station', 'rain_to_gen', 'general_station'].edge_attr = torch.tensor(edge_attributes['rainfall_to_general'], dtype=torch.float32)\n",
    "data['general_station', 'gen_to_gen', 'general_station'].edge_attr = torch.tensor(edge_attributes['general_to_general'], dtype=torch.float32)\n",
    "data['rainfall_station', 'rain_to_rain', 'rainfall_station'].edge_attr = torch.tensor(edge_attributes['rainfall_to_rainfall'], dtype=torch.float32)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(edge_attributes['rainfall_to_rainfall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ea151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process edge indices\n",
    "print(data)\n",
    "print(data.edge_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['general_station', 'gen_to_rain', 'rainfall_station'].edge_attr) \n",
    "print(data['rainfall_station', 'rain_to_gen', 'general_station'].edge_index) \n",
    "print(data['general_station', 'gen_to_gen', 'general_station'].edge_index) \n",
    "print(len(set(data['rainfall_station', 'rain_to_rain', 'rainfall_station'].edge_index.detach().numpy()[0])) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.has_isolated_nodes())\n",
    "print(data.has_self_loops())\n",
    "print(data.is_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['general_station', 'gen_to_rain', 'rainfall_station']['edge_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f959a81",
   "metadata": {},
   "source": [
    "# Creating the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131359f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gnn import HeteroGNN, HeteroGNN2\n",
    "\n",
    "model = HeteroGNN2(hidden_channels=8, out_channels=1,\n",
    "                  num_layers=3)\n",
    "\n",
    "model.to(device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "def collate_temporal_graphs(batch):\n",
    "  gen_x = torch.stack([item['gen_x'] for item in batch])\n",
    "  rain_x = torch.stack([item['rain_x'] for item in batch])\n",
    "  gen_y = torch.stack([item['gen_y'] for item in batch])\n",
    "  rain_y = torch.stack([item['rain_y'] for item in batch])\n",
    "  \n",
    "  return {\n",
    "      'gen_x': gen_x,\n",
    "      'rain_x': rain_x,\n",
    "      'gen_y': gen_y,\n",
    "      'rain_y': rain_y\n",
    "  }\n",
    "\n",
    "def train_epoch(model, data, dataloader, optimizer, device):\n",
    "  model.train()\n",
    "  total_training_loss = 0\n",
    "\n",
    "  train_gen_mask = torch.tensor(data['general_station'].train_mask, dtype=torch.bool).to(device)\n",
    "  train_rain_mask = torch.tensor(data['rainfall_station'].train_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  test_gen_mask = torch.tensor(data['general_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  test_rain_mask = torch.tensor(data['rainfall_station'].test_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  val_gen_mask = torch.tensor(data['general_station'].val_mask, dtype=torch.bool).to(device)\n",
    "  val_rain_mask = torch.tensor(data['rainfall_station'].val_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  edge_index_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "  }\n",
    "\n",
    "  edge_attribute_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_attr_dict.items()\n",
    "  }\n",
    "  for batch in tqdm.tqdm(dataloader, desc=\"training\"):\n",
    "    gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "    rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "    gen_y = batch['gen_y'].to(device)\n",
    "    rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "    batch_size = gen_x.shape[0]\n",
    "\n",
    "    batch_loss = 0\n",
    "    for i in range(batch_size):\n",
    "\n",
    "      gen_x_masked=gen_x[i].clone()\n",
    "      rain_x_masked=rain_x[i].clone()\n",
    " \n",
    "      gen_x_masked[val_gen_mask] = 0\n",
    "      rain_x_masked[val_rain_mask] = 0\n",
    "      gen_x_masked[test_gen_mask] = 0\n",
    "      rain_x_masked[test_rain_mask] = 0\n",
    "\n",
    "      # x_dict = {\n",
    "      #   'general_station': gen_x[i],\n",
    "      #   'rainfall_station': rain_x[i]\n",
    "      # }\n",
    "      x_dict = {\n",
    "        'general_station': gen_x_masked,\n",
    "        'rainfall_station': rain_x_masked,\n",
    "      }\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      out = model(x_dict, edge_index_dict, edge_attribute_dict)\n",
    "\n",
    "\n",
    "      gen_predictions = out['general_station'][train_gen_mask]\n",
    "      rain_predictions = out['rainfall_station'][train_rain_mask]\n",
    "\n",
    "\n",
    "      training_loss = F.mse_loss(gen_predictions, gen_y[i][train_gen_mask]) + F.mse_loss(rain_predictions, rain_y[i][train_rain_mask])\n",
    "      batch_loss += training_loss\n",
    "\n",
    "    batch_loss = batch_loss / batch_size \n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    total_training_loss += batch_loss.item()\n",
    " \n",
    "  return total_training_loss/len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data, dataloader, device):\n",
    "  total_validation_loss = 0\n",
    "\n",
    "  val_gen_mask = torch.tensor(data['general_station'].val_mask, dtype=torch.bool).to(device)\n",
    "  val_rain_mask = torch.tensor(data['rainfall_station'].val_mask, dtype=torch.bool).to(device)\n",
    "  test_gen_mask = torch.tensor(data['general_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  test_rain_mask = torch.tensor(data['rainfall_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  train_gen_mask = torch.tensor(data['general_station'].train_mask, dtype=torch.bool).to(device)\n",
    "  train_rain_mask = torch.tensor(data['rainfall_station'].train_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  edge_index_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "  }\n",
    "  edge_attr_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_attr_dict.items()\n",
    "  }\n",
    "  for batch in tqdm.tqdm(dataloader, desc=\"validation\"):\n",
    "    gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "    rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "    gen_y = batch['gen_y'].to(device)\n",
    "    rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "    batch_size = gen_x.shape[0]\n",
    "\n",
    "    batch_loss = 0\n",
    "    for i in range(batch_size):\n",
    "      gen_x_masked=gen_x[i].clone()\n",
    "      rain_x_masked=rain_x[i].clone()\n",
    "\n",
    "      gen_x_masked[test_gen_mask] = 0\n",
    "      rain_x_masked[test_rain_mask] = 0\n",
    "      gen_x_masked[train_gen_mask] = 0\n",
    "      rain_x_masked[train_rain_mask] = 0\n",
    "      # x_dict = {\n",
    "      #   'general_station': gen_x[i],\n",
    "      #   'rainfall_station': rain_x[i]\n",
    "      # }\n",
    "      x_dict = {\n",
    "        'general_station': gen_x_masked,\n",
    "        'rainfall_station': rain_x_masked\n",
    "      }\n",
    "      out = model(x_dict, edge_index_dict, edge_attr_dict)\n",
    "\n",
    "\n",
    "      gen_predictions = out['general_station'][val_gen_mask]\n",
    "      rain_predictions = out['rainfall_station'][val_rain_mask]\n",
    "\n",
    "\n",
    "      validation_loss = F.mse_loss(gen_predictions, gen_y[i][val_gen_mask]) + F.mse_loss(rain_predictions, rain_y[i][val_rain_mask])\n",
    "      \n",
    "  \n",
    "      batch_loss += validation_loss.item()\n",
    "    total_validation_loss += batch_loss\n",
    " \n",
    "  return total_validation_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c428c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random \n",
    "import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "\n",
    "#set seeds\n",
    "seed=123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "batch_size=16\n",
    "train_dataset = WeatherGraphDataset(data, mode='train')\n",
    "val_dataset = WeatherGraphDataset(data, mode='val')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False,\n",
    "  collate_fn=collate_temporal_graphs\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "  val_dataset,\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False,\n",
    "  collate_fn=collate_temporal_graphs\n",
    ")\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "training_loss_arr = []\n",
    "validation_loss_arr = []\n",
    "early = 0\n",
    "mini = 1000\n",
    "stopping_condition = 3\n",
    "epochs=0\n",
    "\n",
    "training_start = time.time()\n",
    "for i in range(20):\n",
    "  print(f'-----EPOCH: {i + 1}-----')\n",
    "  train_loss = train_epoch(model, data, train_loader, optimizer, device)\n",
    "  validation_loss = validate(model, data, test_loader, device)\n",
    "  training_loss_arr.append(train_loss)\n",
    "  validation_loss_arr.append(validation_loss)\n",
    "  if mini >= validation_loss:\n",
    "    mini = validation_loss\n",
    "    early = 0\n",
    "  else:\n",
    "    early += 1\n",
    "  epochs+=1\n",
    "  if early >= stopping_condition:\n",
    "    print(\"Early stop loss\")\n",
    "    break\n",
    "\n",
    "  print(f\"Train Loss: {train_loss:.4f}\")\n",
    "  print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "\n",
    "training_end = time.time()\n",
    "\n",
    "print(f\"Training took {training_end - training_start} seconds over {epochs} epochs\")\n",
    "plt.plot(training_loss_arr, label='training_loss', color='blue')\n",
    "plt.plot(validation_loss_arr, label='validation_loss', color='red')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fdc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(iter(test_loader))['gen_x'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623fbdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(param.numel() for param in model.parameters())\n",
    "print(total_params)\n",
    "print(list(param for param in model.parameters()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35259636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def test_model():\n",
    "  model.eval()\n",
    "  total_rmse = 0\n",
    "\n",
    "  plot_preds = np.array([])\n",
    "  plot_actual = np.array([])\n",
    "\n",
    "  test_dataset = WeatherGraphDataset(data, mode='val')\n",
    "\n",
    "  val_gen_mask = torch.tensor(data['general_station'].val_mask, dtype=torch.bool).to(device)\n",
    "  val_rain_mask = torch.tensor([0 for _ in data['rainfall_station'].val_mask], dtype=torch.bool).to(device)\n",
    "  test_gen_mask = torch.tensor(data['general_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  test_rain_mask = torch.tensor(data['rainfall_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  train_gen_mask = torch.tensor(data['general_station'].train_mask, dtype=torch.bool).to(device)\n",
    "  train_rain_mask = torch.tensor(data['rainfall_station'].train_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  print(test_gen_mask)\n",
    "\n",
    "  edge_index_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "  }\n",
    "\n",
    "  edge_attr_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_attr_dict.items()\n",
    "  }\n",
    "\n",
    "  dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_temporal_graphs\n",
    "  )\n",
    "\n",
    "  count = 0\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(dataloader, desc=\"testing\"):\n",
    "      gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "      rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "      gen_y = batch['gen_y'].to(device)\n",
    "      rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "      batch_size = gen_x.shape[0]\n",
    "\n",
    "      batch_rmse = 0\n",
    "      for i in range(batch_size):\n",
    "\n",
    "        gen_x_masked=gen_x[i].clone()\n",
    "        rain_x_masked=rain_x[i].clone()\n",
    "\n",
    "        gen_x_masked[val_gen_mask] = 0\n",
    "        rain_x_masked[val_rain_mask] = 0\n",
    "        gen_x_masked[test_gen_mask] = 0\n",
    "        rain_x_masked[test_rain_mask] = 0\n",
    "        x_dict = {\n",
    "          'general_station': gen_x_masked,\n",
    "          'rainfall_station': rain_x_masked\n",
    "        }\n",
    "\n",
    "        out = model(x_dict, edge_index_dict, edge_attr_dict)\n",
    "\n",
    "        gen_predictions = out['general_station'][train_gen_mask]\n",
    "        rain_predictions = out['rainfall_station'][train_rain_mask]\n",
    "\n",
    "        gen_targets = gen_y[i][train_gen_mask]\n",
    "        rain_targets = rain_y[i][train_rain_mask]\n",
    "\n",
    "        plot_preds = np.concatenate((plot_preds, gen_predictions.detach().numpy().flatten(), rain_predictions.detach().numpy().flatten()))\n",
    "        plot_actual = np.concatenate((plot_actual, gen_targets.detach().numpy().flatten(), rain_targets.detach().numpy().flatten()))\n",
    "\n",
    "        gen_MSE_arr = (gen_predictions - gen_targets) ** 2\n",
    "        rain_MSE_arr = (rain_predictions - rain_targets) ** 2\n",
    "\n",
    "        all_squared_errors = torch.cat([gen_MSE_arr, rain_MSE_arr])\n",
    "        test_rmse = torch.sqrt(torch.mean(all_squared_errors))\n",
    "\n",
    "        batch_rmse += test_rmse.item()\n",
    "        count += 1\n",
    "\n",
    "      total_rmse += batch_rmse\n",
    " \n",
    "  plt.scatter(x=plot_actual, y=plot_preds)\n",
    "  plot_bound = max(np.nanmax(plot_actual).astype(int),np.nanmax(plot_preds).astype(int))\n",
    "  plt.plot(np.linspace(0,plot_bound,100),\n",
    "            np.linspace(0,plot_bound,100))\n",
    "  plt.xlabel(\"actual rainfall\")\n",
    "  plt.ylabel(\"predicted rainfall\")\n",
    "\n",
    "  mask = ~np.isnan(plot_actual)\n",
    "  pearson_r_global, pearson_p_global = pearsonr(plot_actual[mask], plot_preds[mask])\n",
    "\n",
    "  print(f\"Pearson correlation: {pearson_r_global}\")\n",
    "  return total_rmse/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff01a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = test_model()\n",
    "print(f\"TEST RMSE: {RMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7600b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f606be2d",
   "metadata": {},
   "source": [
    "# Visualisation of output\n",
    "Test event will be 02-05-2025 0415 to 0615\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c852b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_event_data = weather_station_df_pivot.iloc[593:602]\n",
    "print(test_event_data)\n",
    "test_data = data.clone()\n",
    "\n",
    "test_general_station_data = {}\n",
    "test_rainfall_station_data = {}\n",
    "\n",
    "for station in test_event_data.columns.get_level_values(1).unique():\n",
    "    station_cols = test_event_data.xs(station, level=1, axis=1).interpolate(method='linear').fillna(method='ffill').fillna(method='bfill')\n",
    "    if station in general_station:\n",
    "      test_general_station_data[station] = station_cols.values \n",
    "    else:\n",
    "      test_rainfall_station_data[station] = station_cols.values[:, 0:1]\n",
    "# print(test_general_station_data)\n",
    "# print(test_rainfall_station_data)\n",
    "\n",
    "test_general_station_features = []\n",
    "test_rainfall_station_features = []\n",
    "\n",
    "for station in general_station:\n",
    "  if station in test_general_station_data:\n",
    "    station_feat = test_general_station_data[station]\n",
    "    test_general_station_features.append(station_feat)\n",
    "\n",
    "for station in rainfall_station:\n",
    "  if station in test_rainfall_station_data:\n",
    "    station_feat = test_rainfall_station_data[station]\n",
    "    test_rainfall_station_features.append(station_feat)\n",
    "\n",
    "# print(test_general_station_features)\n",
    "# print(test_rainfall_station_features)\n",
    "\n",
    "test_data['general_station'].x = torch.tensor(np.array(test_general_station_features).transpose(1,0,2), dtype=torch.float)\n",
    "test_data['general_station'].y = torch.tensor(np.array(test_general_station_features)[:, :,0:1].transpose(1,0,2), dtype=torch.float)\n",
    "test_data['rainfall_station'].x = torch.tensor(np.array(test_rainfall_station_features).transpose(1,0,2), dtype=torch.float) \n",
    "test_data['rainfall_station'].y = torch.tensor(np.array(test_rainfall_station_features).transpose(1,0,2), dtype=torch.float)  \n",
    "\n",
    "out = model(test_data.x_dict, test_data.edge_index_dict, test_data.edge_attr_dict)\n",
    "gen_out = out['general_station'].detach().numpy()\n",
    "rain_out = out['rainfall_station'].detach().numpy()\n",
    "\n",
    "out_np = np.concatenate([gen_out, rain_out], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca57f6f",
   "metadata": {},
   "source": [
    "# Visualise rain on radar grid\n",
    "Hard coded to plot only consequitive 9 timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_np / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import *\n",
    "from src.visualisation import *\n",
    "radar_df = load_radar_dataset('radar_vis')\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize=(15,12), subplot_kw={'projection' : ccrs.PlateCarree()})\n",
    "\n",
    "bounds_singapore = {\n",
    "  'left': 103.6,\n",
    "  'right': 104.1,\n",
    "  'top': 1.5,\n",
    "  'bottom': 1.188\n",
    "}\n",
    "bounds = [0.1, 0.2, 0.5, 1, 2, 4, 7, 10, 20] \n",
    "norm = mpl.colors.BoundaryNorm(boundaries=bounds, ncolors=256, extend='both')\n",
    "\n",
    "out_np = out_np / 12\n",
    "for idx, timestamp in enumerate(out_np):\n",
    "  output = {}\n",
    "  count = 0\n",
    "  \n",
    "  for stn in general_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  for stn in rainfall_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  axi = ax[idx // 3][idx % 3]\n",
    "  node_df = pd.Series(output)\n",
    "  node_df = pandas_to_geodataframe(node_df)\n",
    "  visualise_gauge_grid(node_df=node_df, ax=axi)\n",
    "  improved_visualise_radar_grid(radar_df.iloc[idx], ax=axi, zoom=bounds_singapore, norm=norm)\n",
    "  visualise_singapore_outline(ax=axi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rainfall_rates = weather_station_df_pivot.iloc[1773:1797].resample('15min').first()['rain_rate']\n",
    "\n",
    "\n",
    "print(original_rainfall_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_arr = []\n",
    "pred_arr = []\n",
    "\n",
    "for idx, timestamp in enumerate(out):\n",
    "  output = {}\n",
    "  count = 0\n",
    "  a_arr = []\n",
    "  p_arr = []\n",
    "  \n",
    "  for stn in general_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  for stn in rainfall_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "\n",
    "  for key, value in output.items():\n",
    "    a_arr.append(original_rainfall_rates.iloc[idx][key])\n",
    "    p_arr.append(output[key])\n",
    "  a_arr = list(map(lambda x: float(x), a_arr))\n",
    "  actual_arr.append(a_arr)\n",
    "  pred_arr.append(p_arr)\n",
    "\n",
    "actual_arr = np.array(actual_arr)\n",
    "pred_arr = np.array(pred_arr)\n",
    "\n",
    "print(actual_arr)\n",
    "print(pred_arr)\n",
    "error = []\n",
    "for i in range(len(actual_arr)):\n",
    "  error.append(np.nanmean(actual_arr - pred_arr) ** 2)\n",
    "\n",
    "MSE = np.mean(np.array(error))\n",
    "print(MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_rainfall_rates.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a9450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
