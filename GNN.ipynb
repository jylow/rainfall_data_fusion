{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.sampling.main import stratified_spatial_sampling_dual\n",
    "from dataset.weather_graph_dataset import WeatherGraphDataset\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from src.raingauge.utils import (\n",
    "    get_station_coordinate_mappings,\n",
    "    load_weather_station_dataset,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from scipy.stats import pearsonr\n",
    "from src.radar.utils import load_radar_dataset\n",
    "from src.visualization.main import pandas_to_geodataframe, visualise_singapore_outline\n",
    "from src.visualization.radar import improved_visualise_radar_grid\n",
    "from src.visualization.raingauge import visualise_gauge_grid\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_data = load_weather_station_dataset('weather_station_data.csv')\n",
    "weather_station_locations = get_station_coordinate_mappings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(weather_station_locations.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a431912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(weather_station_data['gid'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b30b43",
   "metadata": {},
   "source": [
    "# Preprocess station data.\n",
    "Some stations only contain rainfall information but some stations contain both rainfall and other information.\n",
    "We will split these stations into weather station and general stations \n",
    "\n",
    "Additional info: \n",
    "  Windspeed\n",
    "  Wind Direction\n",
    "  Temperature\n",
    "  Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99070e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(weather_station_data.columns)\n",
    "cols.remove('time_sgt')\n",
    "cols.remove('gid')\n",
    "\n",
    "weather_station_df_pivot = pd.pivot(data=weather_station_data, index='time_sgt', columns='gid', values=cols).resample('15min').first()\n",
    "weather_station_df_pivot['rain_rate'] = weather_station_df_pivot['rain_rate'] * 12\n",
    "weather_station_df_counts = weather_station_df_pivot.count().reset_index()\n",
    "\n",
    "weather_station_info = pd.pivot(data=weather_station_df_counts, index='gid', columns = 'level_0')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "rainfall_station = [row[0] for row in weather_station_info.iterrows() if 0 in row[1].value_counts()]\n",
    "general_station = [s for s in weather_station_locations if s not in rainfall_station]\n",
    "\n",
    "print(rainfall_station)\n",
    "print(general_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in weather_station_df_pivot['rain_rate'].iterrows():\n",
    "  if np.nansum(row[1].to_numpy()) != 0:\n",
    "    count += 1\n",
    "print(f\"Number of timesteps that contain rain: {count}\")\n",
    "print(f\"Total_timesteps = {weather_station_df_pivot.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "general_station_data = {}\n",
    "rainfall_station_data = {}\n",
    "for station in weather_station_df_pivot.columns.get_level_values(1).unique():\n",
    "    station_cols = weather_station_df_pivot.xs(station, level=1, axis=1).interpolate(method='linear').fillna(method='ffill').fillna(method='bfill')\n",
    "    if station in general_station:\n",
    "      general_station_data[station] = station_cols.values\n",
    "    else:\n",
    "      rainfall_station_data[station] = station_cols.values[:, 0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04741f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_station_temp = [stn for stn in general_station if stn != \"S108\"]\n",
    "general_station = general_station_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26124db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "general_station_features = []\n",
    "rainfall_station_features = []\n",
    "for station in general_station:\n",
    "  station_feat = general_station_data[station]\n",
    "  general_station_features.append(station_feat)\n",
    "\n",
    "for station in rainfall_station:\n",
    "  station_feat = rainfall_station_data[station]\n",
    "  rainfall_station_features.append(station_feat)\n",
    "\n",
    "dtype = torch.float32\n",
    "data['general_station'].x = torch.tensor(np.array(general_station_features).transpose(1, 0, 2), dtype=dtype)\n",
    "data['rainfall_station'].x = torch.tensor(np.array(rainfall_station_features).transpose(1,0,2), dtype=dtype)\n",
    "\n",
    "data['general_station'].y = torch.tensor(np.array(general_station_features)[:,:,0:1].transpose(1,0,2), dtype=dtype)\n",
    "data['rainfall_station'].y = torch.tensor(np.array(rainfall_station_features).transpose(1,0,2), dtype=dtype)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853908c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_info = stratified_spatial_sampling_dual(weather_station_locations, seed=1111)\n",
    "print(split_info)\n",
    "\n",
    "data['general_station'].train_mask = [1 if station in split_info['ml']['train'] else 0 for station in general_station]\n",
    "data['general_station'].val_mask = [1 if station in split_info['ml']['validation'] else 0 for station in general_station]\n",
    "data['general_station'].test_mask = [1 if (x == 0 and y == 0) else 0 for x,y in zip(data['general_station'].train_mask, data['general_station'].val_mask)]\n",
    "\n",
    "data['rainfall_station'].train_mask = [1 if station in split_info['ml']['train'] else 0 for station in rainfall_station]\n",
    "data['rainfall_station'].val_mask = [1 if station in split_info['ml']['validation'] else 0 for station in rainfall_station]\n",
    "data['rainfall_station'].test_mask = [1 if (x == 0 and y == 0) else 0 for x,y in zip(data['rainfall_station'].train_mask, data['rainfall_station'].val_mask)]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae33c3",
   "metadata": {},
   "source": [
    "# Edge generation\n",
    "We consider the location of the stations when performing our edge generation. \n",
    "General station locations and rainfall station locations will be considered the same and we will make a connection across the nodes if required. This will ensure that we can connect both the layers together in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_distance(a, b):\n",
    "  return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable to determine number of neighbours per node\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "K = 4\n",
    "\n",
    "ids = general_station + rainfall_station\n",
    "print(ids)\n",
    "\n",
    "coordinates = []\n",
    "for id in ids:\n",
    "  coordinates.append(weather_station_locations[id])\n",
    "coords = np.array(coordinates)\n",
    "\n",
    "print(coords)\n",
    "knn = NearestNeighbors(n_neighbors=K+1, algorithm='ball_tree')\n",
    "knn.fit(coords)\n",
    "\n",
    "distances, indices = knn.kneighbors(coords)\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "edges = {\n",
    "        'rainfall_to_rainfall': [],  \n",
    "        'rainfall_to_general': [],    \n",
    "        'general_to_rainfall': [],  \n",
    "        'general_to_general': []      \n",
    "    }\n",
    "\n",
    "edge_attributes = {\n",
    "        'rainfall_to_rainfall': [],  \n",
    "        'rainfall_to_general': [],    \n",
    "        'general_to_rainfall': [],  \n",
    "        'general_to_general': []      \n",
    "}\n",
    "\n",
    "#add station coordinates for nx plotting\n",
    "for idx, station in enumerate(general_station + rainfall_station):\n",
    "  G.add_node(idx, pos=(weather_station_locations[station][1], weather_station_locations[station][0]))\n",
    "color_map = ['green' for i in range(len(general_station))] + ['red' for i in range(len(rainfall_station))]\n",
    "\n",
    "for idx, row in enumerate(indices):\n",
    "  origin = row[0]\n",
    "  \n",
    "  for n in row[1:]: \n",
    "    G.add_edge(origin, n)\n",
    "    if ids[origin] in rainfall_station:\n",
    "      start_id = rainfall_station.index(ids[origin])\n",
    "      if ids[n] in rainfall_station:\n",
    "        end_id = rainfall_station.index(ids[n])\n",
    "        edges['rainfall_to_rainfall'].append([start_id, end_id])\n",
    "        edge_attributes['rainfall_to_rainfall'].append([get_distance(weather_station_locations[ids[origin]], weather_station_locations[ids[n]])])\n",
    "      else:\n",
    "        end_id = general_station.index(ids[n])\n",
    "        edges['rainfall_to_general'].append([start_id, end_id])\n",
    "        edge_attributes['rainfall_to_general'].append([get_distance(weather_station_locations[ids[origin]], weather_station_locations[ids[n]])])\n",
    "    else:\n",
    "      start_id = general_station.index(ids[origin])\n",
    "      if ids[n] in rainfall_station:\n",
    "        end_id = rainfall_station.index(ids[n])\n",
    "        edges['general_to_rainfall'].append([start_id, end_id])\n",
    "        edge_attributes['general_to_rainfall'].append([get_distance(weather_station_locations[ids[origin]], weather_station_locations[ids[n]])])\n",
    "      else:\n",
    "        end_id = general_station.index(ids[n])\n",
    "        edges['general_to_general'].append([start_id, end_id])\n",
    "        edge_attributes['general_to_general'].append([get_distance(weather_station_locations[ids[origin]], weather_station_locations[ids[n]])])\n",
    "\n",
    "print(G)\n",
    "print(len(list(nx.connected_components(G))))\n",
    "nx.draw(G, nx.get_node_attributes(G, 'pos'), node_color = color_map, with_labels=True, font_weight='bold')\n",
    "\n",
    "for key, val in edges.items():\n",
    "  xarr = []\n",
    "  yarr = []\n",
    "  for x, y in val:\n",
    "    xarr.append(x)\n",
    "    yarr.append(y)\n",
    "  edges[key] = [xarr, yarr]\n",
    "\n",
    "\n",
    "data['general_station', 'gen_to_rain', 'rainfall_station'].edge_index = torch.tensor(edges['general_to_rainfall'], dtype=torch.int64)\n",
    "data['rainfall_station', 'rain_to_gen', 'general_station'].edge_index = torch.tensor(edges['rainfall_to_general'], dtype=torch.int64)\n",
    "data['general_station', 'gen_to_gen', 'general_station'].edge_index = torch.tensor(edges['general_to_general'], dtype=torch.int64)\n",
    "data['rainfall_station', 'rain_to_rain', 'rainfall_station'].edge_index = torch.tensor(edges['rainfall_to_rainfall'], dtype=torch.int64)\n",
    "\n",
    "data['general_station', 'gen_to_rain', 'rainfall_station'].edge_attr = torch.tensor(edge_attributes['general_to_rainfall'], dtype=torch.float32)\n",
    "data['rainfall_station', 'rain_to_gen', 'general_station'].edge_attr = torch.tensor(edge_attributes['rainfall_to_general'], dtype=torch.float32)\n",
    "data['general_station', 'gen_to_gen', 'general_station'].edge_attr = torch.tensor(edge_attributes['general_to_general'], dtype=torch.float32)\n",
    "data['rainfall_station', 'rain_to_rain', 'rainfall_station'].edge_attr = torch.tensor(edge_attributes['rainfall_to_rainfall'], dtype=torch.float32)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(edge_attributes['rainfall_to_rainfall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ea151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process edge indices\n",
    "print(data)\n",
    "print(data.edge_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['general_station', 'gen_to_rain', 'rainfall_station'].edge_attr) \n",
    "print(data['rainfall_station', 'rain_to_gen', 'general_station'].edge_index) \n",
    "print(data['general_station', 'gen_to_gen', 'general_station'].edge_index) \n",
    "print(len(set(data['rainfall_station', 'rain_to_rain', 'rainfall_station'].edge_index.detach().numpy()[0])) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.has_isolated_nodes())\n",
    "print(data.has_self_loops())\n",
    "print(data.is_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['general_station', 'gen_to_rain', 'rainfall_station']['edge_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f959a81",
   "metadata": {},
   "source": [
    "# Creating the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131359f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gnn import HeteroGNN, HeteroGNN2, HeteroSAGEGNN, HeteroGCNGNN\n",
    "\n",
    "model = HeteroGNN2(hidden_channels=4, out_channels=1,\n",
    "                  num_layers=5)\n",
    "\n",
    "model.to(device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "def collate_temporal_graphs(batch):\n",
    "  gen_x = torch.stack([item['gen_x'] for item in batch])\n",
    "  rain_x = torch.stack([item['rain_x'] for item in batch])\n",
    "  gen_y = torch.stack([item['gen_y'] for item in batch])\n",
    "  rain_y = torch.stack([item['rain_y'] for item in batch])\n",
    "\n",
    "  metastation_mask = batch[0]['metastation_mask']\n",
    "  rainfallstation_mask = batch[0]['rainfallstation_mask']\n",
    "  edge_index_dict = batch[0]['edge_index_dict']\n",
    "  edge_attribute_dict = batch[0]['edge_attr_dict']\n",
    "\n",
    "  return {\n",
    "      'gen_x': gen_x,\n",
    "      'rain_x': rain_x,\n",
    "      'gen_y': gen_y,\n",
    "      'rain_y': rain_y,\n",
    "      'metastation_mask': metastation_mask,\n",
    "      'rainfallstation_mask': rainfallstation_mask,\n",
    "      'edge_index_dict': edge_index_dict,\n",
    "      'edge_attr_dict': edge_attribute_dict\n",
    "  }\n",
    "\n",
    "def train_epoch(model, data, dataloader, optimizer, device):  \n",
    "  model.train()\n",
    "  losses = []\n",
    "\n",
    "  charge_bar = tqdm.tqdm(dataloader, desc='training')\n",
    "  '''\n",
    "  This is fake batching... AI suggested doing it before I realised it did nothing...\n",
    "  Currently a lot of copying of data structure. Might be able to do optimization with this.\n",
    "  '''\n",
    "  for batch in charge_bar:\n",
    "      # reset gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      edge_index_dict = batch[\"edge_index_dict\"]\n",
    "      edge_attribute_dict = batch[\"edge_attr_dict\"]\n",
    "\n",
    "      for i in range(batch['gen_x'].shape[0]):\n",
    "\n",
    "          train_metastation_mask = torch.tensor(batch['metastation_mask'], dtype=torch.bool).to(device)\n",
    "          train_rainfallstation_mask = torch.tensor(batch['rainfallstation_mask'], dtype=torch.bool).to(device)\n",
    "          step_loss = []\n",
    "\n",
    "          training_metastation_indices = train_metastation_mask.nonzero(as_tuple=False)\n",
    "          training_rainfallstation_indices = train_rainfallstation_mask.nonzero(as_tuple=False)\n",
    "          gen_x = batch['gen_x']  # [batch_size, num_gen_nodes, gen_features]\n",
    "          rain_x = batch['rain_x']  # [batch_size, num_rain_nodes, rain_features]\n",
    "          gen_y = batch['gen_y']\n",
    "          rain_y = batch['rain_y']\n",
    "\n",
    "          #Start by indiviually masking metastations\n",
    "          for idx in training_metastation_indices:\n",
    "              gen_x_masked=gen_x[i].clone()\n",
    "              rain_x_masked=rain_x[i].clone()\n",
    "      \n",
    "              gen_x_masked[~train_metastation_mask.bool()] = 0\n",
    "              rain_x_masked[~train_rainfallstation_mask.bool()] = 0\n",
    "              gen_x_masked[idx] = 0\n",
    "\n",
    "              x_dict = {\n",
    "              'general_station': gen_x_masked,\n",
    "              'rainfall_station': rain_x_masked,\n",
    "              }\n",
    "              optimizer.zero_grad()\n",
    "              out = model(x_dict, edge_index_dict, edge_attribute_dict)\n",
    "\n",
    "              # Model prediction\n",
    "              gen_predictions = out['general_station'][idx]\n",
    "              gen_actual = gen_y[i][idx]\n",
    "\n",
    "              training_loss = F.mse_loss(gen_predictions, gen_actual) \n",
    "              step_loss.append(training_loss)\n",
    "\n",
    "          #Indiviually mask rain stations\n",
    "          for idx in training_rainfallstation_indices:\n",
    "              gen_x_masked=gen_x[i].clone()\n",
    "              rain_x_masked=rain_x[i].clone()\n",
    "      \n",
    "              #Mask stations that are not training stations\n",
    "              gen_x_masked[~train_metastation_mask.bool()] = 0\n",
    "              rain_x_masked[~train_rainfallstation_mask.bool()] = 0\n",
    "              #Mask the selected rainfall station\n",
    "              rain_x_masked[idx] = 0\n",
    "\n",
    "              x_dict = {\n",
    "              'general_station': gen_x_masked,\n",
    "              'rainfall_station': rain_x_masked,\n",
    "              }\n",
    "              optimizer.zero_grad()\n",
    "              out = model(x_dict, edge_index_dict, edge_attribute_dict)\n",
    "\n",
    "              # Model prediction\n",
    "              rain_predictions = out['rainfall_station'][idx]\n",
    "              rainfall_actual = rain_y[i][idx]\n",
    "\n",
    "              training_loss = F.mse_loss(rain_predictions, rainfall_actual)\n",
    "              step_loss.append(training_loss)\n",
    "          \n",
    "          loss = torch.stack(step_loss).mean()\n",
    "          losses.append(loss.detach())\n",
    "\n",
    "          #backpropagate\n",
    "          loss.backward()\n",
    "\n",
    "          # Update weights\n",
    "          optimizer.step()\n",
    "\n",
    "\n",
    "  losses = torch.stack(losses).mean().item()\n",
    "\n",
    "  return losses\n",
    "\n",
    "\n",
    "'''\n",
    "Below is the code for the sampling method if we wanna use it later\n",
    "'''\n",
    "# def train_epoch(model, data, dataloader, optimizer, device):\n",
    "#   model.train()\n",
    "#   total_training_loss = 0\n",
    "\n",
    "#   train_gen_mask = torch.tensor(data['general_station'].train_mask, dtype=torch.bool).to(device)\n",
    "#   train_rain_mask = torch.tensor(data['rainfall_station'].train_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "#   test_gen_mask = torch.tensor(data['general_station'].test_mask, dtype=torch.bool).to(device)\n",
    "#   test_rain_mask = torch.tensor(data['rainfall_station'].test_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "#   val_gen_mask = torch.tensor(data['general_station'].val_mask, dtype=torch.bool).to(device)\n",
    "#   val_rain_mask = torch.tensor(data['rainfall_station'].val_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "#   edge_index_dict = {\n",
    "#     key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "#   }\n",
    "\n",
    "#   edge_attribute_dict = {\n",
    "#     key:val.to(device) for key, val in data.edge_attr_dict.items()\n",
    "#   }\n",
    "#   for batch in tqdm.tqdm(dataloader, desc=\"training\"):\n",
    "#     gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "#     rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "#     gen_y = batch['gen_y'].to(device)\n",
    "#     rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "#     batch_size = gen_x.shape[0]\n",
    "\n",
    "#     batch_loss = 0.0\n",
    "#     count = 0\n",
    "#     for i in range(batch_size):\n",
    "#       training_metastation_indices = train_gen_mask.nonzero(as_tuple=False)\n",
    "#       training_rainfallstation_indices = train_rain_mask.nonzero(as_tuple=False)\n",
    "#       sampling_ratio = 0.8\n",
    "\n",
    "#       for idx in range(5):\n",
    "#         # Create mask for the stations whose values we want to predict and not use as input\n",
    "#         # Sampling is done instead of training node by node just to make it train through epochs faster        \n",
    "#         samples = math.floor((training_metastation_indices.numel() + training_rainfallstation_indices.numel()) * sampling_ratio)\n",
    "#         mask_positions = torch.randperm(training_metastation_indices.numel() + training_rainfallstation_indices.numel())[0:samples]\n",
    "#         metastation_indices = training_metastation_indices[mask_positions[mask_positions < training_metastation_indices.numel()]].flatten()\n",
    "#         rainfallstation_indices = training_rainfallstation_indices[mask_positions[mask_positions >= training_metastation_indices.numel()] - training_metastation_indices.numel()].flatten()\n",
    "\n",
    "#         gen_x_masked=gen_x[i].clone()\n",
    "#         rain_x_masked=rain_x[i].clone()\n",
    "  \n",
    "#         gen_x_masked[val_gen_mask] = 0\n",
    "#         rain_x_masked[val_rain_mask] = 0\n",
    "#         gen_x_masked[test_gen_mask] = 0\n",
    "#         rain_x_masked[test_rain_mask] = 0\n",
    "#         gen_x_masked[metastation_indices] = 0\n",
    "#         rain_x_masked[rainfallstation_indices] = 0\n",
    "\n",
    "#         x_dict = {\n",
    "#           'general_station': gen_x_masked,\n",
    "#           'rainfall_station': rain_x_masked,\n",
    "#         }\n",
    "#         # print(x_dict)\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(x_dict, edge_index_dict, edge_attribute_dict)\n",
    "\n",
    "\n",
    "#         gen_predictions = out['general_station'][metastation_indices]\n",
    "#         rain_predictions = out['rainfall_station'][rainfallstation_indices]\n",
    "#         gen_actual = gen_y[i][metastation_indices]\n",
    "#         rainfall_actual = rain_y[i][rainfallstation_indices]\n",
    "\n",
    "#         #Deals with case that all station of one type is masked and tensor is [] causing nan\n",
    "#         if metastation_indices.numel() == 0:\n",
    "#           gen_predictions = torch.zeros(1, device=device)\n",
    "#           gen_actual= torch.zeros(1, device=device)\n",
    "#         if rainfallstation_indices.numel() == 0:\n",
    "#           rain_predictions = torch.zeros(1, device=device)\n",
    "#           rainfall_actual = torch.zeros(1, device=device)\n",
    "          \n",
    "\n",
    "#         training_loss = F.mse_loss(gen_predictions, gen_actual) + F.mse_loss(rain_predictions, rainfall_actual)\n",
    "#         batch_loss += training_loss\n",
    "#         count += rain_predictions.numel() + gen_predictions.numel()\n",
    "\n",
    "#     batch_loss = batch_loss / count\n",
    "#     batch_loss.backward()\n",
    "#     optimizer.step()\n",
    "#     total_training_loss += batch_loss.item()\n",
    " \n",
    "#   return total_training_loss/len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data, dataloader, device):\n",
    "  total_validation_loss = 0\n",
    "\n",
    "  val_gen_mask = torch.tensor(data['general_station'].val_mask, dtype=torch.bool).to(device)\n",
    "  val_rain_mask = torch.tensor(data['rainfall_station'].val_mask, dtype=torch.bool).to(device)\n",
    "  test_gen_mask = torch.tensor(data['general_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  test_rain_mask = torch.tensor(data['rainfall_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  train_gen_mask = torch.tensor(data['general_station'].train_mask, dtype=torch.bool).to(device)\n",
    "  train_rain_mask = torch.tensor(data['rainfall_station'].train_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  edge_index_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "  }\n",
    "  edge_attr_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_attr_dict.items()\n",
    "  }\n",
    "  for batch in tqdm.tqdm(dataloader, desc=\"validation\"):\n",
    "    gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "    rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "    gen_y = batch['gen_y'].to(device)\n",
    "    rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "    batch_size = gen_x.shape[0]\n",
    "\n",
    "    batch_loss = 0\n",
    "    for i in range(batch_size):\n",
    "      gen_x_masked=gen_x[i].clone()\n",
    "      rain_x_masked=rain_x[i].clone()\n",
    "\n",
    "      gen_x_masked[test_gen_mask] = 0\n",
    "      rain_x_masked[test_rain_mask] = 0\n",
    "      gen_x_masked[train_gen_mask] = 0\n",
    "      rain_x_masked[train_rain_mask] = 0\n",
    "      x_dict = {\n",
    "        'general_station': gen_x_masked,\n",
    "        'rainfall_station': rain_x_masked\n",
    "      }\n",
    "      out = model(x_dict, edge_index_dict, edge_attr_dict)\n",
    "\n",
    "\n",
    "      gen_predictions = out['general_station'][val_gen_mask]\n",
    "      rain_predictions = out['rainfall_station'][val_rain_mask]\n",
    "\n",
    "\n",
    "      validation_loss = F.mse_loss(gen_predictions, gen_y[i][val_gen_mask]) + F.mse_loss(rain_predictions, rain_y[i][val_rain_mask])\n",
    "      \n",
    "  \n",
    "      batch_loss += validation_loss.item()\n",
    "    total_validation_loss += batch_loss\n",
    " \n",
    "  return total_validation_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c428c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 546/546 [53:50<00:00,  5.92s/it]\n",
      "validation: 100%|██████████| 546/546 [00:35<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11.3348\n",
      "Validation Loss: 314.3675\n",
      "-----EPOCH: 2-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 546/546 [49:58<00:00,  5.49s/it]\n",
      "validation: 100%|██████████| 546/546 [00:36<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.9915\n",
      "Validation Loss: 304.3825\n",
      "-----EPOCH: 3-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 546/546 [6:30:40<00:00, 42.93s/it]     \n",
      "validation: 100%|██████████| 546/546 [00:33<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.7137\n",
      "Validation Loss: 291.1006\n",
      "-----EPOCH: 4-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 546/546 [48:51<00:00,  5.37s/it]\n",
      "validation: 100%|██████████| 546/546 [00:34<00:00, 15.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.5713\n",
      "Validation Loss: 267.3552\n",
      "-----EPOCH: 5-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 546/546 [8:38:54<00:00, 57.02s/it]     \n",
      "validation: 100%|██████████| 546/546 [00:36<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.4170\n",
      "Validation Loss: 296.1156\n",
      "-----EPOCH: 6-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 546/546 [4:19:37<00:00, 28.53s/it]      \n",
      "validation: 100%|██████████| 546/546 [00:35<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.2880\n",
      "Validation Loss: 279.6191\n",
      "-----EPOCH: 7-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   1%|          | 4/546 [00:27<1:02:08,  6.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m20\u001b[39m):\n\u001b[32m     45\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m-----EPOCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-----\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m   train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m   validation_loss = validate(model, data, test_loader, device)\n\u001b[32m     48\u001b[39m   training_loss_arr.append(train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, data, dataloader, optimizer, device)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# print(x_dict)\u001b[39;00m\n\u001b[32m     86\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attribute_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Model prediction\u001b[39;00m\n\u001b[32m     90\u001b[39m rain_predictions = out[\u001b[33m'\u001b[39m\u001b[33mrainfall_station\u001b[39m\u001b[33m'\u001b[39m][idx]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FYP/rainfall_data_fusion/models/gnn.py:83\u001b[39m, in \u001b[36mHeteroGNN2.forward\u001b[39m\u001b[34m(self, x_dict, edge_index_dict, edge_attributes_dict)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_dict, edge_index_dict, edge_attributes_dict):\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# First layer: aggregate from original features\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convs:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         x_dict = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m                        \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attributes_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m         x_dict = {key: x.relu() \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict.items()}\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     89\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mgeneral_station\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.lin_general(x_dict[\u001b[33m'\u001b[39m\u001b[33mgeneral_station\u001b[39m\u001b[33m'\u001b[39m]),\n\u001b[32m     90\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mrainfall_station\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.lin_rainfall(x_dict[\u001b[33m'\u001b[39m\u001b[33mrainfall_station\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     91\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch_geometric/nn/conv/hetero_conv.py:158\u001b[39m, in \u001b[36mHeteroConv.forward\u001b[39m\u001b[34m(self, *args_dict, **kwargs_dict)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m out = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[32m    161\u001b[39m     out_dict[dst] = [out]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch_geometric/nn/conv/gat_conv.py:308\u001b[39m, in \u001b[36mGATConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lin_src \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lin_dst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    307\u001b[39m         x_src = \u001b[38;5;28mself\u001b[39m.lin_src(x).view(-\u001b[32m1\u001b[39m, H, C)\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m         x_dst = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin_dst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.view(-\u001b[32m1\u001b[39m, H, C)\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Tuple of source and target node features:\u001b[39;00m\n\u001b[32m    311\u001b[39m     x_src, x_dst = x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/fyp/lib/python3.13/site-packages/torch_geometric/nn/dense/linear.py:147\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    142\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[32m    143\u001b[39m \n\u001b[32m    144\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[33;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random \n",
    "import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "\n",
    "#set seeds\n",
    "seed=123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "batch_size=16\n",
    "train_dataset = WeatherGraphDataset(data, mode='train')\n",
    "val_dataset = WeatherGraphDataset(data, mode='val')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False,\n",
    "  collate_fn=collate_temporal_graphs\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "  val_dataset,\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False,\n",
    "  collate_fn=collate_temporal_graphs\n",
    ")\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "training_loss_arr = []\n",
    "validation_loss_arr = []\n",
    "early = 0\n",
    "mini = 1000\n",
    "stopping_condition = 5\n",
    "epochs=0\n",
    "\n",
    "training_start = time.time()\n",
    "for i in range(20):\n",
    "  print(f'-----EPOCH: {i + 1}-----')\n",
    "  train_loss = train_epoch(model, data, train_loader, optimizer, device)\n",
    "  validation_loss = validate(model, data, test_loader, device)\n",
    "  training_loss_arr.append(train_loss)\n",
    "  validation_loss_arr.append(validation_loss)\n",
    "  if mini >= validation_loss:\n",
    "    mini = validation_loss\n",
    "    early = 0\n",
    "  else:\n",
    "    early += 1\n",
    "  epochs+=1\n",
    "  if early >= stopping_condition:\n",
    "    print(\"Early stop loss\")\n",
    "    break\n",
    "\n",
    "  print(f\"Train Loss: {train_loss:.4f}\")\n",
    "  print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "\n",
    "training_end = time.time()\n",
    "\n",
    "print(f\"Training took {training_end - training_start} seconds over {epochs} epochs\")\n",
    "plt.plot(training_loss_arr, label='training_loss', color='blue')\n",
    "plt.plot(validation_loss_arr, label='validation_loss', color='red')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c18fdc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 15, 5])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(test_loader))['gen_x'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "623fbdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858\n",
      "[Parameter containing:\n",
      "tensor([[[ 0.3776, -0.2419, -0.5865,  0.0973]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 1.0539, -0.6409, -0.6901, -0.6703]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 2.2956,  1.3808,  0.0000, -0.2074], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.4735,  0.4016, -0.7263,  0.3698, -0.6781],\n",
      "        [-1.5733,  0.1610,  0.5151, -0.2241,  0.0759],\n",
      "        [-0.7048, -0.9019, -0.6623, -0.3474, -0.8022],\n",
      "        [ 0.8512, -0.0139,  0.3836,  0.0563, -0.2018]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2086,  0.8874, -0.2698,  0.3030, -0.2341],\n",
      "        [ 0.5906,  0.5394, -0.8596,  0.6474,  0.2544],\n",
      "        [ 0.3641,  0.2280,  0.5750, -0.1512, -0.8235],\n",
      "        [-0.2234, -0.6821, -0.0483, -0.1981, -0.5712]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.3447,  0.3561, -1.1757, -0.0461]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.5287,  0.8591,  0.6698,  0.7379]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.7555, 0.0205, 0.0357, 0.2467], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.5558,  1.2843,  0.0660,  0.1403, -0.0314],\n",
      "        [ 1.0422,  0.4508,  0.5585,  0.0658,  0.1189],\n",
      "        [ 0.4838, -0.4559, -0.6771, -1.2820, -0.8536],\n",
      "        [ 1.4943, -0.0964, -0.5151,  0.1878,  0.7176]], requires_grad=True), Parameter containing:\n",
      "tensor([[-1.0396],\n",
      "        [-0.7197],\n",
      "        [-0.4206],\n",
      "        [ 0.0562]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.3722,  0.7948, -0.2871,  1.0849]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.5951, -0.9295, -0.3704,  0.9644]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 2.2956,  1.3808,  0.0000, -0.2074], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.7263],\n",
      "        [-1.3730],\n",
      "        [-1.3665],\n",
      "        [ 1.2894]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.7544,  0.4624, -0.6312, -0.6872,  0.3820],\n",
      "        [-0.0041,  0.3827, -0.7371, -0.0155,  0.5479],\n",
      "        [ 0.3317,  0.0582,  0.2088, -0.0513, -0.5007],\n",
      "        [-0.2862, -0.5452,  0.6175,  0.4163,  0.3135]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.9921, -0.3087,  0.6321, -0.0473]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.3878,  0.8530, -0.2061, -0.0634]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.7555, 0.0205, 0.0357, 0.2467], requires_grad=True), Parameter containing:\n",
      "tensor([[-2.7455],\n",
      "        [ 1.3337],\n",
      "        [ 0.9615],\n",
      "        [ 0.9465]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2186],\n",
      "        [ 0.4488],\n",
      "        [ 0.8585],\n",
      "        [ 0.5259]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.2273,  0.5380, -0.2313, -0.6505]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.5493,  0.7454, -0.0296,  0.3331]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5576,  0.4643, -0.8802,  0.0975], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2969, -0.7798,  0.6598, -1.0062],\n",
      "        [-0.1630, -1.0416, -0.2020,  0.2333],\n",
      "        [-0.0767,  1.6384,  0.4288,  0.8259],\n",
      "        [ 0.5990, -0.4038,  0.4463, -0.0938]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1521, -0.2843, -0.6635,  0.0660],\n",
      "        [ 0.5808,  0.3602, -0.2696,  0.3046],\n",
      "        [ 1.2968,  0.0340,  0.8232, -0.0882],\n",
      "        [ 0.6202, -0.1210,  0.2419,  0.7377]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.9079,  0.3216, -0.2847, -0.0099]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.4574,  0.7811, -0.7066, -1.0075]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.8454, 0.3753, 0.7571, 0.6506], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2196, -0.1009,  0.0049, -0.5376],\n",
      "        [-0.5953, -0.9037,  0.3829,  0.7388],\n",
      "        [ 0.3502,  0.8114,  0.0042, -0.2118],\n",
      "        [ 0.9261,  1.5852,  0.1312, -0.6298]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.3432,  0.2553, -0.6744, -0.6509],\n",
      "        [-0.7489, -0.4860,  0.0973,  0.5969],\n",
      "        [ 0.5232,  0.8574, -0.5788,  0.0750],\n",
      "        [-0.5752,  0.6919,  0.1440,  0.8401]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 1.4066, -0.4858, -0.4599,  0.2802]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-1.3239,  1.0361, -0.9500, -0.3202]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5576,  0.4643, -0.8802,  0.0975], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.9094,  0.6980,  0.1072,  0.7175],\n",
      "        [-1.0969,  0.7777,  0.8084,  1.0583],\n",
      "        [-0.3923, -1.7928, -0.1304, -0.0748],\n",
      "        [-0.8075, -0.3566, -0.7765, -0.4612]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 1.7265,  1.1727, -0.0529, -0.0655],\n",
      "        [-0.5215, -1.8723, -0.6682, -0.1856],\n",
      "        [ 0.4494,  1.4386,  0.6119, -0.9459],\n",
      "        [ 0.0506, -0.0392,  0.3267,  0.6148]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.3570, -0.4084,  0.6662, -0.0953]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.4530, -0.7965, -0.4848,  0.1216]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.8454, 0.3753, 0.7571, 0.6506], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1898,  0.2207,  1.2853,  0.3134],\n",
      "        [ 0.2102,  0.8631,  0.1465,  0.6634],\n",
      "        [ 1.1527, -0.1095, -0.3182,  0.0094],\n",
      "        [ 0.6754, -0.0862, -0.8772,  0.0470]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0134, -0.4089,  0.3372, -0.9979],\n",
      "        [ 0.5373,  0.2134,  0.1999, -0.2038],\n",
      "        [ 0.3639,  0.5058, -0.8969, -0.3415],\n",
      "        [ 1.2722,  0.0640,  0.2535, -0.6650]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.5881,  0.2506,  0.9263, -1.4562]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.6013,  0.1892, -0.4874, -0.3743]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7963, -0.0158, -0.4733, -0.6429], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2941, -0.9789,  1.9496,  0.0065],\n",
      "        [-0.4962, -0.3541, -0.6340,  0.4717],\n",
      "        [-0.3464, -0.6143,  1.0922, -0.2008],\n",
      "        [-0.7783,  0.8254,  0.0283, -0.2678]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.5899,  0.2670,  0.6535,  0.7927],\n",
      "        [-0.6556, -0.6410,  0.6743,  0.4233],\n",
      "        [ 0.5397, -0.1931,  0.7461, -0.7119],\n",
      "        [-0.0376,  0.2496,  0.1455, -0.6535]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.3447, -0.6987,  0.3329, -0.2073]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-1.0386, -0.5845, -0.5972,  0.8264]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.3355,  0.4640, -0.1991,  0.8303], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.9563,  0.9722, -1.0456, -0.1982],\n",
      "        [-0.4711,  0.8237,  0.2484,  1.0727],\n",
      "        [ 0.2341, -0.2140,  0.2690, -0.1952],\n",
      "        [-0.1847,  0.6006,  0.4873,  0.2495]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0613, -0.8021, -0.4078, -0.7246],\n",
      "        [-0.2907, -0.8151,  0.5128, -1.1421],\n",
      "        [ 1.0412, -0.4941, -0.2403,  0.3379],\n",
      "        [ 0.1165, -0.2078, -0.5245,  0.0299]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-1.1182,  0.5302,  0.1414, -0.5529]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.5703, -1.1640,  0.6077, -0.6444]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7963, -0.0158, -0.4733, -0.6429], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.4104, -1.0453,  0.1255, -0.3237],\n",
      "        [ 0.4497,  0.9728, -0.1353, -0.7548],\n",
      "        [ 0.4241, -0.4010, -0.4473, -0.6880],\n",
      "        [ 1.0512,  0.0298, -0.4072,  0.5601]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.4067, -1.2218, -1.2496,  0.1325],\n",
      "        [ 0.2914,  0.7081,  0.3395,  0.9934],\n",
      "        [-0.6342, -0.2498, -1.3189, -0.6760],\n",
      "        [ 0.6523,  0.1156,  0.2624, -0.1909]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.1546,  0.1377,  0.2837, -0.7293]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.1759,  0.6400, -0.1605,  0.7064]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.3355,  0.4640, -0.1991,  0.8303], requires_grad=True), Parameter containing:\n",
      "tensor([[ 1.3601,  0.8307, -0.4502, -1.8237],\n",
      "        [ 0.8318,  0.5643, -1.7050, -1.3643],\n",
      "        [ 0.5715, -0.6041, -0.7608,  0.3506],\n",
      "        [ 0.8435,  0.4963, -1.1544, -1.2064]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.7776,  0.0353, -0.1117,  0.8212],\n",
      "        [-0.3847, -1.0389, -0.7765,  0.6942],\n",
      "        [-0.4861,  0.5549,  0.3452, -0.2169],\n",
      "        [ 0.7454, -0.4795,  0.8352, -0.0735]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.1738,  0.2105, -0.6660,  0.7262]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.1727,  0.3100,  0.4603, -0.4192]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3037, -0.3341, -0.3432,  0.1509], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1523, -0.3100, -0.3578,  0.0814],\n",
      "        [ 0.5364,  0.2870,  1.0740,  0.6334],\n",
      "        [-0.8129, -0.3683,  0.1834, -0.1030],\n",
      "        [ 2.0757, -0.1958,  1.4835, -1.7197]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3561, -0.5296,  0.7741,  0.1283],\n",
      "        [-0.2257, -0.0848, -0.0890,  0.0500],\n",
      "        [-0.5344,  0.1009,  0.2400,  0.3989],\n",
      "        [ 0.1451,  0.1371, -0.6143,  0.7821]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.5139,  0.5411,  0.5856,  0.2704]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.4941,  0.2699, -1.2734,  0.1432]]], requires_grad=True), Parameter containing:\n",
      "tensor([1.3477, 0.2877, 0.1861, 0.0716], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.5194, -0.3234,  0.8803,  0.9009],\n",
      "        [-0.6603,  0.0575, -0.5308,  0.2856],\n",
      "        [ 0.3512, -0.6616, -0.7727,  1.2306],\n",
      "        [-0.6974, -1.3115,  0.8787, -0.6650]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.7818,  0.6368, -0.3722,  0.0393],\n",
      "        [ 0.8127, -0.3918,  0.8411,  0.6504],\n",
      "        [ 0.7293,  0.2707, -0.4323,  0.5505],\n",
      "        [-0.6981, -0.5465, -0.3801,  0.3323]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.1530,  0.5411, -0.3520, -0.6956]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-1.0019,  0.8253,  0.6981,  0.3906]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3037, -0.3341, -0.3432,  0.1509], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1507,  0.7527,  0.1738,  0.1793],\n",
      "        [ 0.3631, -0.8642, -0.8343, -0.9693],\n",
      "        [ 0.6145,  1.1299, -0.3951,  0.6144],\n",
      "        [-0.5797, -0.1113, -0.1201, -0.3984]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.7497,  0.4084,  0.1149, -0.2072],\n",
      "        [ 0.9311, -0.6407,  0.3966,  0.8220],\n",
      "        [-0.2161, -0.8254, -0.0649, -0.6329],\n",
      "        [ 0.6948, -0.4770, -0.6265,  0.4260]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-1.6492, -0.4301,  0.3472,  1.2280]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.3509, -0.1845,  1.0852, -0.5026]]], requires_grad=True), Parameter containing:\n",
      "tensor([1.3477, 0.2877, 0.1861, 0.0716], requires_grad=True), Parameter containing:\n",
      "tensor([[-9.7897e-01, -1.1512e+00,  4.6642e-01, -8.7281e-04],\n",
      "        [ 5.4125e-01,  1.0042e+00,  2.1351e-01,  1.2269e+00],\n",
      "        [-1.3864e-01,  9.4171e-01,  8.5813e-01, -6.7493e-01],\n",
      "        [ 2.2840e-01, -1.2897e-01,  9.8397e-01,  2.2743e-01]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.8713,  1.0044, -0.1524,  0.7065],\n",
      "        [-0.4061,  0.0079,  0.0706, -0.6583],\n",
      "        [-1.1761, -1.0829, -1.1538, -0.6501],\n",
      "        [ 0.0610,  0.7201,  0.3370, -0.7068]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 1.6827,  0.9293, -1.3146,  0.0627]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.5406,  0.2895, -0.7917,  1.3020]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1612,  0.7004,  0.3243,  0.2654], requires_grad=True), Parameter containing:\n",
      "tensor([[-5.6175e-01, -2.6350e-01, -3.9080e-01, -1.8049e+00],\n",
      "        [-8.3730e-01,  8.4143e-01,  4.9274e-01,  2.4517e-01],\n",
      "        [ 1.4144e-03,  1.4655e-01,  5.2299e-01,  2.7426e+00],\n",
      "        [ 1.1022e-01,  3.8950e-01,  9.4855e-02,  5.6506e-01]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0728,  0.1203, -0.3881,  0.0598],\n",
      "        [ 0.0762,  0.0038, -0.6280, -0.6692],\n",
      "        [-0.7497,  0.6585,  0.7868,  0.8712],\n",
      "        [ 0.3487, -0.4503,  0.0782, -0.8805]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.4233, -1.1575,  0.0815,  0.1397]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.3421, -0.0881,  0.0947, -0.9026]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3852, 0.4156, 0.4743, 0.0675], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.3600,  0.0191, -0.6419,  0.5712],\n",
      "        [-1.0451, -0.6779, -0.6310,  0.0975],\n",
      "        [ 0.0917, -0.5448,  0.0746,  0.5509],\n",
      "        [ 0.4447, -0.3999,  0.9987,  0.0107]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 1.5629,  0.8832,  1.4368,  0.3513],\n",
      "        [ 1.2125, -0.2948,  1.2070,  0.9878],\n",
      "        [-1.5249,  0.0376,  0.4538, -0.2925],\n",
      "        [ 1.5601,  1.0288,  0.4914,  0.8159]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.8676, -0.7182, -0.4350, -0.3429]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 1.0823, -1.2819,  1.2842,  1.2134]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1612,  0.7004,  0.3243,  0.2654], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1717, -0.6252, -0.0666,  0.5584],\n",
      "        [-0.3104, -0.0820,  0.5728,  0.5758],\n",
      "        [-2.6147,  1.1829, -1.2782,  0.4200],\n",
      "        [ 0.4398, -0.1231, -0.6584,  0.8807]], requires_grad=True), Parameter containing:\n",
      "tensor([[-1.1327, -0.4939, -0.6540, -2.4124],\n",
      "        [ 1.2646,  0.8322,  1.0770,  2.2762],\n",
      "        [-1.3168,  0.7767, -0.4992, -2.2888],\n",
      "        [-1.0658,  0.2388, -0.0978, -1.9740]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.7280,  0.8046,  1.4732, -0.6592]]], requires_grad=True), Parameter containing:\n",
      "tensor([[[-1.2316, -1.5741,  1.0312, -1.5557]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3852, 0.4156, 0.4743, 0.0675], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.4999, -0.0805, -0.0228,  0.8260],\n",
      "        [ 0.0839, -0.1112, -1.3327,  0.8698],\n",
      "        [-0.7551,  1.1766, -1.2046,  0.7399],\n",
      "        [-0.1411, -0.1457, -0.2035,  0.5581]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 2.0780,  0.1339,  1.4514,  0.6899],\n",
      "        [ 2.2219,  1.0779,  0.4917, -0.5000],\n",
      "        [-1.6345, -0.0836, -0.1777,  0.6441],\n",
      "        [ 2.2477,  0.8018,  1.4195,  0.1349]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.4551, -0.5730,  0.6575,  0.4391]], requires_grad=True), Parameter containing:\n",
      "tensor([0.1993], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1627, -1.2942,  0.4365, -0.6136]], requires_grad=True), Parameter containing:\n",
      "tensor([0.9986], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(param.numel() for param in model.parameters())\n",
    "print(total_params)\n",
    "print(list(param for param in model.parameters()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35259636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def test_model():\n",
    "  model.eval()\n",
    "  total_rmse = 0\n",
    "\n",
    "  plot_preds = np.array([])\n",
    "  plot_actual = np.array([])\n",
    "\n",
    "  test_dataset = WeatherGraphDataset(data, mode='val')\n",
    "\n",
    "  val_gen_mask = torch.tensor(data['general_station'].val_mask, dtype=torch.bool).to(device)\n",
    "  val_rain_mask = torch.tensor([0 for _ in data['rainfall_station'].val_mask], dtype=torch.bool).to(device)\n",
    "  test_gen_mask = torch.tensor(data['general_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  test_rain_mask = torch.tensor(data['rainfall_station'].test_mask, dtype=torch.bool).to(device)\n",
    "  train_gen_mask = torch.tensor(data['general_station'].train_mask, dtype=torch.bool).to(device)\n",
    "  train_rain_mask = torch.tensor(data['rainfall_station'].train_mask, dtype=torch.bool).to(device)\n",
    "\n",
    "  print(test_gen_mask)\n",
    "\n",
    "  edge_index_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_index_dict.items()\n",
    "  }\n",
    "\n",
    "  edge_attr_dict = {\n",
    "    key:val.to(device) for key, val in data.edge_attr_dict.items()\n",
    "  }\n",
    "\n",
    "  dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_temporal_graphs\n",
    "  )\n",
    "\n",
    "  count = 0\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(dataloader, desc=\"testing\"):\n",
    "      gen_x = batch['gen_x'].to(device)  # [batch_size, num_gen_nodes, gen_features]\n",
    "      rain_x = batch['rain_x'].to(device)  # [batch_size, num_rain_nodes, rain_features]\n",
    "      gen_y = batch['gen_y'].to(device)\n",
    "      rain_y = batch['rain_y'].to(device)\n",
    "\n",
    "      batch_size = gen_x.shape[0]\n",
    "\n",
    "      batch_rmse = 0\n",
    "      for i in range(batch_size):\n",
    "\n",
    "        gen_x_masked=gen_x[i].clone()\n",
    "        rain_x_masked=rain_x[i].clone()\n",
    "\n",
    "        gen_x_masked[val_gen_mask] = 0\n",
    "        rain_x_masked[val_rain_mask] = 0\n",
    "        gen_x_masked[test_gen_mask] = 0\n",
    "        rain_x_masked[test_rain_mask] = 0\n",
    "        x_dict = {\n",
    "          'general_station': gen_x_masked,\n",
    "          'rainfall_station': rain_x_masked\n",
    "        }\n",
    "\n",
    "        out = model(x_dict, edge_index_dict, edge_attr_dict)\n",
    "\n",
    "        gen_predictions = out['general_station'][train_gen_mask]\n",
    "        rain_predictions = out['rainfall_station'][train_rain_mask]\n",
    "\n",
    "        gen_targets = gen_y[i][train_gen_mask]\n",
    "        rain_targets = rain_y[i][train_rain_mask]\n",
    "\n",
    "        plot_preds = np.concatenate((plot_preds, gen_predictions.detach().numpy().flatten(), rain_predictions.detach().numpy().flatten()))\n",
    "        plot_actual = np.concatenate((plot_actual, gen_targets.detach().numpy().flatten(), rain_targets.detach().numpy().flatten()))\n",
    "\n",
    "        gen_MSE_arr = (gen_predictions - gen_targets) ** 2\n",
    "        rain_MSE_arr = (rain_predictions - rain_targets) ** 2\n",
    "\n",
    "        all_squared_errors = torch.cat([gen_MSE_arr, rain_MSE_arr])\n",
    "        test_rmse = torch.sqrt(torch.mean(all_squared_errors))\n",
    "\n",
    "        batch_rmse += test_rmse.item()\n",
    "        count += 1\n",
    "\n",
    "      total_rmse += batch_rmse\n",
    " \n",
    "  plt.scatter(x=plot_actual, y=plot_preds)\n",
    "  plot_bound = max(np.nanmax(plot_actual).astype(int),np.nanmax(plot_preds).astype(int))\n",
    "  plt.plot(np.linspace(0,plot_bound,100),\n",
    "            np.linspace(0,plot_bound,100))\n",
    "  plt.xlabel(\"actual rainfall\")\n",
    "  plt.ylabel(\"predicted rainfall\")\n",
    "\n",
    "  mask = ~np.isnan(plot_actual)\n",
    "  pearson_r_global, pearson_p_global = pearsonr(plot_actual[mask], plot_preds[mask])\n",
    "\n",
    "  print(f\"Pearson correlation: {pearson_r_global}\")\n",
    "  return total_rmse/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ff01a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 8736/8736 [00:31<00:00, 278.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.5646569967818486\n",
      "TEST RMSE: 1.6390015473879274\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE = test_model()\n",
    "print(f\"TEST RMSE: {RMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7600b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f606be2d",
   "metadata": {},
   "source": [
    "# Visualisation of output\n",
    "Test event will be 02-05-2025 0415 to 0615\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c852b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_event_data = weather_station_df_pivot.iloc[593:602]\n",
    "print(test_event_data)\n",
    "test_data = data.clone()\n",
    "\n",
    "test_general_station_data = {}\n",
    "test_rainfall_station_data = {}\n",
    "\n",
    "for station in test_event_data.columns.get_level_values(1).unique():\n",
    "    station_cols = test_event_data.xs(station, level=1, axis=1).interpolate(method='linear').fillna(method='ffill').fillna(method='bfill')\n",
    "    if station in general_station:\n",
    "      test_general_station_data[station] = station_cols.values \n",
    "    else:\n",
    "      test_rainfall_station_data[station] = station_cols.values[:, 0:1]\n",
    "# print(test_general_station_data)\n",
    "# print(test_rainfall_station_data)\n",
    "\n",
    "test_general_station_features = []\n",
    "test_rainfall_station_features = []\n",
    "\n",
    "for station in general_station:\n",
    "  if station in test_general_station_data:\n",
    "    station_feat = test_general_station_data[station]\n",
    "    test_general_station_features.append(station_feat)\n",
    "\n",
    "for station in rainfall_station:\n",
    "  if station in test_rainfall_station_data:\n",
    "    station_feat = test_rainfall_station_data[station]\n",
    "    test_rainfall_station_features.append(station_feat)\n",
    "\n",
    "# print(test_general_station_features)\n",
    "# print(test_rainfall_station_features)\n",
    "\n",
    "test_data['general_station'].x = torch.tensor(np.array(test_general_station_features).transpose(1,0,2), dtype=torch.float)\n",
    "test_data['general_station'].y = torch.tensor(np.array(test_general_station_features)[:, :,0:1].transpose(1,0,2), dtype=torch.float)\n",
    "test_data['rainfall_station'].x = torch.tensor(np.array(test_rainfall_station_features).transpose(1,0,2), dtype=torch.float) \n",
    "test_data['rainfall_station'].y = torch.tensor(np.array(test_rainfall_station_features).transpose(1,0,2), dtype=torch.float)  \n",
    "\n",
    "out = model(test_data.x_dict, test_data.edge_index_dict, test_data.edge_attr_dict)\n",
    "gen_out = out['general_station'].detach().numpy()\n",
    "rain_out = out['rainfall_station'].detach().numpy()\n",
    "\n",
    "out_np = np.concatenate([gen_out, rain_out], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca57f6f",
   "metadata": {},
   "source": [
    "# Visualise rain on radar grid\n",
    "Hard coded to plot only consequitive 9 timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_np / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import *\n",
    "from src.visualisation import *\n",
    "radar_df = load_radar_dataset('radar_vis')\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize=(15,12), subplot_kw={'projection' : ccrs.PlateCarree()})\n",
    "\n",
    "bounds_singapore = {\n",
    "  'left': 103.6,\n",
    "  'right': 104.1,\n",
    "  'top': 1.5,\n",
    "  'bottom': 1.188\n",
    "}\n",
    "bounds = [0.1, 0.2, 0.5, 1, 2, 4, 7, 10, 20] \n",
    "norm = mpl.colors.BoundaryNorm(boundaries=bounds, ncolors=256, extend='both')\n",
    "\n",
    "out_np = out_np / 12\n",
    "for idx, timestamp in enumerate(out_np):\n",
    "  output = {}\n",
    "  count = 0\n",
    "  \n",
    "  for stn in general_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  for stn in rainfall_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  axi = ax[idx // 3][idx % 3]\n",
    "  node_df = pd.Series(output)\n",
    "  node_df = pandas_to_geodataframe(node_df)\n",
    "  visualise_gauge_grid(node_df=node_df, ax=axi)\n",
    "  improved_visualise_radar_grid(radar_df.iloc[idx], ax=axi, zoom=bounds_singapore, norm=norm)\n",
    "  visualise_singapore_outline(ax=axi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rainfall_rates = weather_station_df_pivot.iloc[1773:1797].resample('15min').first()['rain_rate']\n",
    "\n",
    "\n",
    "print(original_rainfall_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_arr = []\n",
    "pred_arr = []\n",
    "\n",
    "for idx, timestamp in enumerate(out):\n",
    "  output = {}\n",
    "  count = 0\n",
    "  a_arr = []\n",
    "  p_arr = []\n",
    "  \n",
    "  for stn in general_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "  for stn in rainfall_station:\n",
    "    output[stn] = float(timestamp[count])\n",
    "    count += 1\n",
    "\n",
    "  for key, value in output.items():\n",
    "    a_arr.append(original_rainfall_rates.iloc[idx][key])\n",
    "    p_arr.append(output[key])\n",
    "  a_arr = list(map(lambda x: float(x), a_arr))\n",
    "  actual_arr.append(a_arr)\n",
    "  pred_arr.append(p_arr)\n",
    "\n",
    "actual_arr = np.array(actual_arr)\n",
    "pred_arr = np.array(pred_arr)\n",
    "\n",
    "print(actual_arr)\n",
    "print(pred_arr)\n",
    "error = []\n",
    "for i in range(len(actual_arr)):\n",
    "  error.append(np.nanmean(actual_arr - pred_arr) ** 2)\n",
    "\n",
    "MSE = np.mean(np.array(error))\n",
    "print(MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_rainfall_rates.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a9450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
